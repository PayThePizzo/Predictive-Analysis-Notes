---
title: "CT0429 - Analisi Predittiva - aa 21/22 - Appello I"
author: "Nome Cognome - matricola"
output: 
  html_document: 
    toc: yes
---

# Istruzioni

Salvate questo file con il nome `matricola.Rmd`. Questo sarà il file che dovrete consegnare. Il file deve compilare senza problemi: files che non possono essere compilati correttamente saranno penalizzati. 


Per essere sicuri di poter trovare il file al momento della consegna potete controllare dove è il file quando compilate il file la prima volta usando il comando `getwd()`. 

```{r, eval=TRUE}
getwd()
## da cancellare quando siete sicuri di dove è il file
```


Attenzione - per tutto l'esame, se non specificato esplicitamente, il livello di significatività da usare è $\alpha = 0.02$


# Esercizio 1

Il data-scientist di un'azienda che produce app ludiche per cellulari vuole costruire un modello predittivo per il tempo in cui gli utenti hanno usato l'app. Dal dataset disponibile estrae i records delle persone che, nel periodo di Gennaio-Marzo 2021 hanno dichiarato al momento dell'iscrizione di voler condividere con l'azienda l'informazione sulla loro età: questo identifica 70 utenti per cui sono disponibili le seguenti informazioni: 

* `numAccess`: il numero totale di accessi eseguiti all'app dall'utente nell'anno 2021
* `age`: l'età dichiarata dall'utente
* `time`: il tempo passato dall'utente usando l'app 

La variabile `time` è la variabile di interesse (variabile risposta). 

Tutte le informazioni a disposizione dell'analista sono disponibili nel dataset `dex1` che si può caricare usando il seguente codice: 

```{r,cache=TRUE}
dex1 <- read.csv("ex1_data.csv", header = TRUE)
```

### Es. 1.a 


```{r, solution = TRUE}
fit1 <- lm(time~., data = dex1)
summary(fit1)
```

Il modello è altamente significativo e il valore di $R^2$ è molto alto: il modello spiega una ampia proporzione della variabilità nei dati. Si nota inoltre che solo una delle variabili esplicative risulta significativa. 


### Es. 1.b 


```{r,solution=TRUE}
fit2 <- lm(time ~ numAccess, data = dex1)
anova(fit2, fit1)
```

Usando anova per confrontare fit1 e fit2 (che sono due modelli annidati) si verifica l'ipotesi nulla: \[H_0: \beta_{age} = 0 \]
contro l'ipotesi alternativa 
\[H_1: \beta_{age} \neq 0 \]
Si verifica cioè se è possibile eliminare un predittore dal modello (e stimare un parametro in meno) ed ottenere una stima comparabile in termine di errore quadratico medio (RSS). 
Dato che il p-value del test `anova` è molto alto non si può rifiutare l'ipotesi nulla: non vi è evidenza che mantenere la variabile `age` migliori la stima del modello e possiamo quindi eliminare la variabile. 

### Es. 1.c



```{r,solution=TRUE}
cis <- predict(fit2, 
               newdata = data.frame(numAccess = c(60, 200)),
               interval = "confidence")
cis[,3]-cis[,2]
pis <- predict(fit2, 
               newdata =  data.frame(numAccess = c(60, 200)),
               interval = "prediction")
pis[,3]-pis[,2]
summary(dex1$numAccess)
```


Il secondo intervallo di confidenza è più ampio del primo: questo perché non ci sono utenti nel campione che abbiano eseguito 200 accessi: per fare una stima per quel tipo di utente è necessario estrapolare la stima ben oltre i valori con cui il modello è stato stimato e quindi vi è molta incertezza nella stima. 
Questo è vero sia per gli intervalli di confidenza che per gli intervalli di predizione. 
Gli intervalli di confidenza danno un'indicazione dell'incertezza attorno al valore medio del tempo passato da ogni utente nell'app; gli intervalli di predizione invece danno un'indicazione dell'incertezza per quelli che possono essere gli effettivi valori del tempo passato da un utente nell'app. Dato che la media è per definizione meno variabile delle singole osservazioni gli intervalli di confidenza sono meno ampi degli intervalli di predizione.  


### Es. 1.d



Il data scientist ha incluso nell'analisi solo le persone che hanno accettato di condividere con l'azienda l'informazione sulla loro età. Questo gruppo di persone potrebbe non essere rappresentativo della popolazione generale di utenti dell'app, dato che sono probabilmente persone con una alta fidelizzazione nei confronti dell'app. Per poter generalizzare i risultati sarebbe necessario poter essere sicuri che gli utenti che consentono a condividere l'informazione sull'età non si comportino diversamente dagli altri utenti. 


# Esercizio 2

Il gestore di un sistema di rete mantiene un registro di informazioni varie in cui registra anche se in una giornata si sono registrati guasti che richiedono l'intervento di un operatore esterno per ripristinare il sistema. Il file `ex2_data.csv` contiene le seguenti variabili: 


* `numAccess`: il numero di accessi alla rete
* `numRequests`: il numero di richieste gestite dalla rete
* `durationMean`: la durata media di una sessione di un utente
* `durationMax`: la durata massima di una sessione di un utente 
* `durationMin`: la durata minima di una sessione di un utente
* `fail`: un indicatore che ha valore 1 quando si è registrato un guasto che richiede l'intervento di un operatore esterno per ripristinare il sistema 

Si carichi il dataset usando il codice seguente:  

```{r,cache=TRUE}
dex2 <- read.csv("ex2_data.csv", header = TRUE)
```

Si desidera costruire un modello predittivo per la variabile `fail`, un modello cioè che predica se in un giorno sarà necessario l'intervento di un operatore esterno per ripristinare il sistema. 

### Es. 2.a 


```{r, solution = TRUE}
fitTot <- glm(fail ~ ., family = binomial, data = dex2)
summary(fitTot)
```


La stima dei parametri che descrivono l'effetto di numAccess e numRequests è di segno opposto: si stima che al crescere del numero di accessi aumenta la probabilità che si verifichi un guasto, mentre questa probabilità diminuisce all'aumentare del numero di richieste. Quest'ultimo effetto però viene stimato essere poco significativo (quindi non si può rifiutare $H_0: \beta_{numRequests} = 0$).  


### Es. 2.b



```{r, solution = TRUE}
print(step(fitTot, direction = "backward", trace = 0, k = 2))
print(step(fitTot, direction = "backward", trace = 0, k = log(450)))
```

Usando il BIC come criterio per selezionare il modello ottimale si individua un modello che ha meno parametri rispetto a quello individuato usando AIC come criterio. Questo deriva dal fatto che BIC penalizza maggiormente i modelli con molti parametri (specialmente quando log(n) è molto più grande di 2) e tende quindi a identificare come ottimali modelli con meno parametri rispetto ad AIC. 


### Es. 2.c 


```{r}
nd <- data.frame(numAccess = c(10,5290), 
                 numRequests = c(2000,5000), 
                 durationMean = c(10,24.8), 
                 durationMax = c(75,90), 
                 durationMin = c(9,5))
rownames(nd) <- c("day1","day2")
```

```{r, solution = TRUE}
nd <- data.frame(numAccess = c(10,5290), 
                 numRequests = c(2000,5000), 
                 durationMean = c(10,24.8), 
                 durationMax = c(75,90), 
                 durationMin = c(9,5))
rownames(nd) <- c("day1","day2")
```


```{r, solution = TRUE}
predict(fitTot, type = "response", newdata = nd)
preds <- predict(fitTot, type = "link", newdata = nd, se.fit = TRUE)
cbind(binomial()$linkinv(preds$fit + qnorm(0.025)*preds$se.fit),
      binomial()$linkinv(preds$fit + qnorm(0.975)*preds$se.fit))
```


### Es. 2.d


```{r, solution = TRUE}
## proporzione predizione corrette
mean(as.numeric(predict(fitTot, type = "response") > 0.5) == dex2$fail)
## proporzione predizioni sbagliate
mean(as.numeric(predict(fitTot, type = "response") > 0.5) != dex2$fail)
## tabella di contiengenza di predizioni corrette e sbaglate
table(as.numeric(predict(fitTot, type = "response") > 0.5),dex2$fail)
```

Il modello predice in maniera corretta l'evento `guasto` in circa il `r 100*round(mean(as.numeric(predict(fitTot, type = "response") > 0.5) == dex2$fail),3)` \% dei casi. 

