summary(fit)
predict(fit, nd=data.frame(x1=4,x2="a"))
predict(fit, newdata=data.frame(x1=4,x2="a"))
predict(fit, newdata=data.frame(x1=2,x2="b"))
(-2*-217.192)+ 2*3
(-2*-217.192)+ 2*4
(-2*-104.4494)+ 2*4
(-2*-117.6221)+ 2*3
## data(spam, package = "ElemStatLearn")
spam <- read.table("spambase.data", header = FALSE,sep=",")
names(spam) <- c("make", "address", "all", "num3d", "our", "over", "remove",
"internet", "order", "mail", "receive", "will", "people", "report",
"addresses", "free", "business", "email", "you", "credit", "your",
"font", "num000", "money", "hp", "hpl", "george", "num650", "lab",
"labs", "telnet", "num857", "data", "num415", "num85", "technology",
"num1999", "parts", "pm", "direct", "cs", "meeting", "original",
"project", "re", "edu", "table", "conference", "charSemicolon",
"charRoundbracket", "charSquarebracket", "charExclamation", "charDollar",
"charHash", "capitalAve", "capitalLong", "capitalTotal", "type")
table(spam$type)
# Train-Test Split
set.seed(42)
spam_idx <- sample(nrow(spam), 2000)
# train set, used for model selection and diagnostics
spam_trn <- spam[spam_idx,]
# test set, used only at the end for evaluation
spam_tst <- spam[-spam_idx,]
fit_caps <- glm(type ~ capitalTotal,
data <- spam_trn,
family = binomial)
fit_selected <- glm(type ~ edu + money + capitalTotal + charDollar,
data = spam_trn,
family = binomial)
fit_additive <- glm(type ~ .,
data = spam_trn,
family = binomial)
fit_over <- glm(type ~ capitalTotal*(.),
data = spam_trn,
family = binomial, maxit = 120)
# When the estimate for the
# linear predictor is greater than 0,
# we assign the type to spam
par(mfrow=c(1,2))
plot(predict(fit_caps), col = 1 + (predict(fit_caps)>0), pch=1,
main="Misclassification", xlab = "Index", ylab="Estimated Y")
legend(x="topright", legend=c("Not spam","Spam"),
col=c("black","red"), lwd=1, lty=c(NA,NA),
pch=c(1,1))
# Misclassification rate for fit_caps
c("fit_caps misclassification rate",
mean(ifelse(predict(fit_caps) > 0, 1, 0) != spam_trn$type))
# Misclassification rate for fit_selected
c("fit_selected misclassification rate",
mean(ifelse(predict(fit_selected) > 0, 1, 0) != spam_trn$type))
# Misclassification rate for fit_additive
c("fit_additive misclassification rate",
mean(ifelse(predict(fit_additive) > 0, 1, 0) != spam_trn$type))
# Misclassification rate for fit_over
c("fit_over misclassification rate",
mean(ifelse(predict(fit_over) > 0, 1, 0) != spam_trn$type))
## data(spam, package = "ElemStatLearn")
spam <- read.table("spambase.data", header = FALSE,sep=",")
names(spam) <- c("make", "address", "all", "num3d", "our", "over", "remove",
"internet", "order", "mail", "receive", "will", "people", "report",
"addresses", "free", "business", "email", "you", "credit", "your",
"font", "num000", "money", "hp", "hpl", "george", "num650", "lab",
"labs", "telnet", "num857", "data", "num415", "num85", "technology",
"num1999", "parts", "pm", "direct", "cs", "meeting", "original",
"project", "re", "edu", "table", "conference", "charSemicolon",
"charRoundbracket", "charSquarebracket", "charExclamation", "charDollar",
"charHash", "capitalAve", "capitalLong", "capitalTotal", "type")
table(spam$type)
# Train-Test Split
set.seed(42)
spam_idx <- sample(nrow(spam), 2000)
# train set, used for model selection and diagnostics
spam_trn <- spam[spam_idx,]
# test set, used only at the end for evaluation
spam_tst <- spam[-spam_idx,]
fit_caps <- glm(type ~ capitalTotal,
data <- spam_trn,
family = binomial)
fit_selected <- glm(type ~ edu + money + capitalTotal + charDollar,
data = spam_trn,
family = binomial)
fit_additive <- glm(type ~ .,
data = spam_trn,
family = binomial)
fit_over <- glm(type ~ capitalTotal*(.),
data = spam_trn,
family = binomial, maxit = 120)
# When the estimate for the
# linear predictor is greater than 0,
# we assign the type to spam
par(mfrow=c(1,2))
plot(predict(fit_caps), col = 1 + (predict(fit_caps)>0), pch=1,
main="Misclassification", xlab = "Index", ylab="Estimated Y")
legend(x="topright", legend=c("Not spam","Spam"),
col=c("black","red"), lwd=1, lty=c(NA,NA),
pch=c(1,1))
# Misclassification rate for fit_caps
c("fit_caps misclassification rate",
mean(ifelse(predict(fit_caps) > 0, 1, 0) != spam_trn$type))
# Misclassification rate for fit_selected
c("fit_selected misclassification rate",
mean(ifelse(predict(fit_selected) > 0, 1, 0) != spam_trn$type))
# Misclassification rate for fit_additive
c("fit_additive misclassification rate",
mean(ifelse(predict(fit_additive) > 0, 1, 0) != spam_trn$type))
# Misclassification rate for fit_over
c("fit_over misclassification rate",
mean(ifelse(predict(fit_over) > 0, 1, 0) != spam_trn$type))
?boot::cv
?cb
?cb
?cb
?cv
library(boot, lib.loc = "D:/Program Files/R-4.2.2/library")
?var
3/5
1-(3/5)
c([1,2],[3,4])
cbind(c(1,2),c(3,4)
)
mat <- cbind(c(1,2),c(3,4))
mat
mat[,2]
0/4
getwd()
## da cancellare quando siete sicuri di dove è il file
dex1 <- read.csv("ex1_data.csv", header = TRUE)
fit1 <- lm(time~., data = dex1)
summary(fit1)
fit2 <- lm(time ~ numAccess, data = dex1)
anova(fit2, fit1)
cis <- predict(fit2,
newdata = data.frame(numAccess = c(60, 200)),
interval = "confidence")
cis[,3]-cis[,2]
pis <- predict(fit2,
newdata =  data.frame(numAccess = c(60, 200)),
interval = "prediction")
pis[,3]-pis[,2]
summary(dex1$numAccess)
dex2 <- read.csv("ex2_data.csv", header = TRUE)
fitTot <- glm(fail ~ ., family = binomial, data = dex2)
summary(fitTot)
print(step(fitTot, direction = "backward", trace = 0, k = 2))
print(step(fitTot, direction = "backward", trace = 0, k = log(450)))
nd <- data.frame(numAccess = c(10,5290),
numRequests = c(2000,5000),
durationMean = c(10,24.8),
durationMax = c(75,90),
durationMin = c(9,5))
rownames(nd) <- c("day1","day2")
nd <- data.frame(numAccess = c(10,5290),
numRequests = c(2000,5000),
durationMean = c(10,24.8),
durationMax = c(75,90),
durationMin = c(9,5))
rownames(nd) <- c("day1","day2")
predict(fitTot, type = "response", newdata = nd)
preds <- predict(fitTot, type = "link", newdata = nd, se.fit = TRUE)
cbind(binomial()$linkinv(preds$fit + qnorm(0.025)*preds$se.fit),
binomial()$linkinv(preds$fit + qnorm(0.975)*preds$se.fit))
## proporzione predizione corrette
mean(as.numeric(predict(fitTot, type = "response") > 0.5) == dex2$fail)
## proporzione predizioni sbagliate
mean(as.numeric(predict(fitTot, type = "response") > 0.5) != dex2$fail)
## tabella di contiengenza di predizioni corrette e sbaglate
table(as.numeric(predict(fitTot, type = "response") > 0.5),dex2$fail)
# When the estimate for the
# linear predictor is greater than 0,
# we assign the type to spam
par(mfrow=c(1,2))
plot(predict(fit_caps), col = 1 + (predict(fit_caps)>0), pch=1,
main="Misclassification", xlab = "Index", ylab="Estimated Y")
## data(spam, package = "ElemStatLearn")
spam <- read.table("spambase.data", header = FALSE,sep=",")
names(spam) <- c("make", "address", "all", "num3d", "our", "over", "remove",
"internet", "order", "mail", "receive", "will", "people", "report",
"addresses", "free", "business", "email", "you", "credit", "your",
"font", "num000", "money", "hp", "hpl", "george", "num650", "lab",
"labs", "telnet", "num857", "data", "num415", "num85", "technology",
"num1999", "parts", "pm", "direct", "cs", "meeting", "original",
"project", "re", "edu", "table", "conference", "charSemicolon",
"charRoundbracket", "charSquarebracket", "charExclamation", "charDollar",
"charHash", "capitalAve", "capitalLong", "capitalTotal", "type")
table(spam$type)
# Train-Test Split
set.seed(42)
spam_idx <- sample(nrow(spam), 2000)
# train set, used for model selection and diagnostics
spam_trn <- spam[spam_idx,]
# test set, used only at the end for evaluation
spam_tst <- spam[-spam_idx,]
fit_caps <- glm(type ~ capitalTotal,
data <- spam_trn,
family = binomial)
fit_selected <- glm(type ~ edu + money + capitalTotal + charDollar,
data = spam_trn,
family = binomial)
fit_additive <- glm(type ~ .,
data = spam_trn,
family = binomial)
fit_over <- glm(type ~ capitalTotal*(.),
data = spam_trn,
family = binomial, maxit = 120)
# When the estimate for the
# linear predictor is greater than 0,
# we assign the type to spam
par(mfrow=c(1,2))
plot(predict(fit_caps), col = 1 + (predict(fit_caps)>0), pch=1,
main="Misclassification", xlab = "Index", ylab="Estimated Y")
legend(x="topright", legend=c("Not spam","Spam"),
col=c("black","red"), lwd=1, lty=c(NA,NA),
pch=c(1,1))
# Misclassification rate for fit_caps
c("fit_caps misclassification rate",
mean(ifelse(predict(fit_caps) > 0, 1, 0) != spam_trn$type))
# Misclassification rate for fit_selected
c("fit_selected misclassification rate",
mean(ifelse(predict(fit_selected) > 0, 1, 0) != spam_trn$type))
# Misclassification rate for fit_additive
c("fit_additive misclassification rate",
mean(ifelse(predict(fit_additive) > 0, 1, 0) != spam_trn$type))
# Misclassification rate for fit_over
c("fit_over misclassification rate",
mean(ifelse(predict(fit_over) > 0, 1, 0) != spam_trn$type))
cv_class <- function(K=5, dat, model, cutoff = 0.5){
# Ensure to use all the points in the dataset, only once
# Assign each point to one of the k groups
# This way we might have subgroups of different size
assign_group <- rep(seq(1,K), each = floor(nrow(dat)/K))
if(length(assign_group) != nrow(dat)){
assign_group <- c(assign_group, sample(seq(1,K)))[1:nrow(dat)]
}
assign_group <- sample(assign_group, size = nrow(dat))
error <- 0
for(j in 1:K){
# Get subset of observations
whichobs <- (assign_group == j)
#fit a model WITHOUT the hold-out data
folded_model <- suppressWarnings(glm(model$formula,
data = dat[!whichobs,],
family = "binomial"))
# evaluate the model on the hold-out data
fitted <- suppressWarnings(predict(folded_model,
dat[whichobs,],
type="response"))
observed <- dat[whichobs, strsplit(paste(model$formula), "~")[[2]]]
# Misclassification rate
# fitted > cutoff -> spam
error <- error + mean(observed != (fitted>cutoff))/K
# in cv.glm the actual error is calculated as (y - p(y=1))
# error <- error + mean((observed - fitted)^2)/K
}
error
}
set.seed(1)
cv_class(K=5, dat = spam_trn, model = fit_caps)
cv_class(K=5, dat = spam_trn, model = fit_selected)
cv_class(K=5, dat = spam_trn, model = fit_additive)
cv_class(K=5, dat = spam_trn, model = fit_over)
## Automatically through:
# set.seed(1)
# boot::cv.glm(spam_trn, fit_caps, K = 5)$delta[1]
# boot::cv.glm(spam_trn, fit_selected, K = 5)$delta[1]
# boot::cv.glm(spam_trn, fit_additive, K = 5)$delta[1]
# boot::cv.glm(spam_trn, fit_over, K = 5)$delta[1]
## to do cross validation on the actual mis-classification rate
# mycost = function(y, yhat) mean((y != (yhat>0.5)))
# boot::cv.glm(spam_trn, fit_caps, K = 5, cost = mycost)$delta[1]
# boot::cv.glm(spam_trn, fit_selected, K = 5, cost = mycost)$delta[1]
# boot::cv.glm(spam_trn, fit_additive, K = 5, cost = mycost)$delta[1]
# boot::cv.glm(spam_trn, fit_over, K = 5, cost = mycost)$delta[1]
AIC(fit_caps, fit_selected, fit_additive, fit_over, k = log(nrow(spam_trn)))
make_conf_mat <- function(predicted, actual) {
table(predicted = predicted, actual = actual)
}
# make_conf_mat(predicted = predict(fit_additive, type = "r", newdata = spam_tst) > 0.5,
#               actual = spam_tst$type)
spam_tst_pred <- ifelse(
predict(fit_additive, spam_tst) > 0,
1, 0)
spam_tst_pred <- ifelse(
predict(fit_additive, spam_tst, type = "response") > 0.5,
1, 0)
conf_mat_50 <- make_conf_mat(predicted = spam_tst_pred,
actual = spam_tst$type)
conf_mat_50
## data(spam, package = "ElemStatLearn")
spam <- read.table("spambase.data", header = FALSE,sep=",")
names(spam) <- c("make", "address", "all", "num3d", "our", "over", "remove",
"internet", "order", "mail", "receive", "will", "people", "report",
"addresses", "free", "business", "email", "you", "credit", "your",
"font", "num000", "money", "hp", "hpl", "george", "num650", "lab",
"labs", "telnet", "num857", "data", "num415", "num85", "technology",
"num1999", "parts", "pm", "direct", "cs", "meeting", "original",
"project", "re", "edu", "table", "conference", "charSemicolon",
"charRoundbracket", "charSquarebracket", "charExclamation", "charDollar",
"charHash", "capitalAve", "capitalLong", "capitalTotal", "type")
table(spam$type)
# Train-Test Split
set.seed(42)
spam_idx <- sample(nrow(spam), 2000)
# train set, used for model selection and diagnostics
spam_trn <- spam[spam_idx,]
# test set, used only at the end for evaluation
spam_tst <- spam[-spam_idx,]
fit_caps <- glm(type ~ capitalTotal,
data <- spam_trn,
family = binomial)
fit_selected <- glm(type ~ edu + money + capitalTotal + charDollar,
data = spam_trn,
family = binomial)
fit_additive <- glm(type ~ .,
data = spam_trn,
family = binomial)
fit_over <- glm(type ~ capitalTotal*(.),
data = spam_trn,
family = binomial, maxit = 120)
# When the estimate for the
# linear predictor is greater than 0,
# we assign the type to spam
par(mfrow=c(1,2))
plot(predict(fit_caps), col = 1 + (predict(fit_caps)>0), pch=1,
main="Misclassification", xlab = "Index", ylab="Estimated Y")
legend(x="topright", legend=c("Not spam","Spam"),
col=c("black","red"), lwd=1, lty=c(NA,NA),
pch=c(1,1))
# Misclassification rate for fit_caps
c("fit_caps misclassification rate",
mean(ifelse(predict(fit_caps) > 0, 1, 0) != spam_trn$type))
# Misclassification rate for fit_selected
c("fit_selected misclassification rate",
mean(ifelse(predict(fit_selected) > 0, 1, 0) != spam_trn$type))
# Misclassification rate for fit_additive
c("fit_additive misclassification rate",
mean(ifelse(predict(fit_additive) > 0, 1, 0) != spam_trn$type))
# Misclassification rate for fit_over
c("fit_over misclassification rate",
mean(ifelse(predict(fit_over) > 0, 1, 0) != spam_trn$type))
cv_class <- function(K=5, dat, model, cutoff = 0.5){
# Ensure to use all the points in the dataset, only once
# Assign each point to one of the k groups
# This way we might have subgroups of different size
assign_group <- rep(seq(1,K), each = floor(nrow(dat)/K))
if(length(assign_group) != nrow(dat)){
assign_group <- c(assign_group, sample(seq(1,K)))[1:nrow(dat)]
}
assign_group <- sample(assign_group, size = nrow(dat))
error <- 0
for(j in 1:K){
# Get subset of observations
whichobs <- (assign_group == j)
#fit a model WITHOUT the hold-out data
folded_model <- suppressWarnings(glm(model$formula,
data = dat[!whichobs,],
family = "binomial"))
# evaluate the model on the hold-out data
fitted <- suppressWarnings(predict(folded_model,
dat[whichobs,],
type="response"))
observed <- dat[whichobs, strsplit(paste(model$formula), "~")[[2]]]
# Misclassification rate
# fitted > cutoff -> spam
error <- error + mean(observed != (fitted>cutoff))/K
# in cv.glm the actual error is calculated as (y - p(y=1))
# error <- error + mean((observed - fitted)^2)/K
}
error
}
set.seed(1)
cv_class(K=5, dat = spam_trn, model = fit_caps)
cv_class(K=5, dat = spam_trn, model = fit_selected)
cv_class(K=5, dat = spam_trn, model = fit_additive)
cv_class(K=5, dat = spam_trn, model = fit_over)
## Automatically through:
# set.seed(1)
# boot::cv.glm(spam_trn, fit_caps, K = 5)$delta[1]
# boot::cv.glm(spam_trn, fit_selected, K = 5)$delta[1]
# boot::cv.glm(spam_trn, fit_additive, K = 5)$delta[1]
# boot::cv.glm(spam_trn, fit_over, K = 5)$delta[1]
## to do cross validation on the actual mis-classification rate
# mycost = function(y, yhat) mean((y != (yhat>0.5)))
# boot::cv.glm(spam_trn, fit_caps, K = 5, cost = mycost)$delta[1]
# boot::cv.glm(spam_trn, fit_selected, K = 5, cost = mycost)$delta[1]
# boot::cv.glm(spam_trn, fit_additive, K = 5, cost = mycost)$delta[1]
# boot::cv.glm(spam_trn, fit_over, K = 5, cost = mycost)$delta[1]
AIC(fit_caps, fit_selected, fit_additive, fit_over, k = log(nrow(spam_trn)))
make_conf_mat <- function(predicted, actual) {
table(predicted = predicted, actual = actual)
}
# make_conf_mat(predicted = predict(fit_additive, type = "r", newdata = spam_tst) > 0.5,
#               actual = spam_tst$type)
spam_tst_pred <- ifelse(
predict(fit_additive, spam_tst) > 0,
1, 0)
spam_tst_pred <- ifelse(
predict(fit_additive, spam_tst, type = "response") > 0.5,
1, 0)
conf_mat_50 <- make_conf_mat(predicted = spam_tst_pred,
actual = spam_tst$type)
conf_mat_50
# When the estimate for the
# linear predictor is greater than 0,
# we assign the type to spam
par(mfrow=c(1,2))
plot(predict(fit_caps), col = 1 + (predict(fit_caps)>0), pch=1,
main="Misclassification", xlab = "Index", ylab="Estimated Y")
legend(x="topright", legend=c("Not spam","Spam"),
col=c("black","red"), lwd=1, lty=c(NA,NA),
pch=c(1,1))
# When the estimate for the
# linear predictor is greater than 0,
# we assign the type to spam
par(mfrow=c(1,2))
plot(predict(fit_additive), col = 1 + (predict(fit_additive)>0), pch=1,
main="Misclassification", xlab = "Index", ylab="Estimated Y")
legend(x="topright", legend=c("Not spam","Spam"),
col=c("black","red"), lwd=1, lty=c(NA,NA),
pch=c(1,1))
# When the estimate for the
# linear predictor is greater than 0,
# we assign the type to spam
par(mfrow=c(1,2))
plot(predict(fit_caps), col = 1 + (predict(fit_caps)>0), pch=1,
main="Misclassification", xlab = "Index", ylab="Estimated Y")
legend(x="topright", legend=c("Not spam","Spam"),
col=c("black","red"), lwd=1, lty=c(NA,NA),
pch=c(1,1))
plot(predict(fit_caps), col = 1 + (predict(fit_caps)>0), pch=1,
main="Misclassification", xlab = "Index", ylab="Estimated Y")
legend(x="topright", legend=c("Not spam","Spam"),
col=c("black","red"), lwd=1, lty=c(NA,NA),
pch=c(1,1))
# When the estimate for the
# linear predictor is greater than 0,
# we assign the type to spam
par(mfrow=c(1,2))
plot(predict(fit_caps), col = 1 + (predict(fit_caps)>0), pch=1,
main="Misclassification for fit_caps", xlab = "Index", ylab="Estimated Y")
legend(x="topright", legend=c("Not spam","Spam"),
col=c("black","red"), lwd=1, lty=c(NA,NA),
pch=c(1,1))
plot(predict(fit_additive), col = 1 + (predict(fit_additive)>0), pch=1,
main="Misclassification for fit_additive", xlab = "Index", ylab="Estimated Y")
legend(x="topright", legend=c("Not spam","Spam"),
col=c("black","red"), lwd=1, lty=c(NA,NA),
pch=c(1,1))
# When the estimate for the
# linear predictor is greater than 0,
# we assign the type to spam
par(mfrow=c(1,2))
plot(predict(fit_caps), col = 1 + (predict(fit_caps)>0), pch=1,
main="Misclassification for fit_caps", xlab = "Index", ylab="Estimated Y")
legend(x="topright", legend=c("Not spam","Spam"),
col=c("black","red"), lwd=1, lty=c(NA,NA),
pch=c(1,1))
plot(predict(fit_additive), col = 1 + (predict(fit_additive)>0), pch=1,
main="Misclassification for fit_additive", xlab = "Index", ylab="Estimated Y")
legend(x="topright", legend=c("Not spam","Spam"),
col=c("black","red"), lwd=1, lty=c(NA,NA),
pch=c(1,1))
fitted.values(fit_additive)
predict(fit_additive)>0
predict(fit_additive)
coef(fit_additive)
lenght(coef(fit_additive))
length(coef(fit_additive))
((98.933 +  11.241) + ( 0.472 * 72)) + (qt(0.98, df=76)* 1.23)
(0.472-0.5)/0.0246
TS <- (0.472-0.5)/0.0246
abs(TS) > qt(1-(0.02/2), df=76)
qt(1-(0.02/2), df=76)
qt(c(0.02/2,1-(0.02/2), df=76)
)
qt(c(0.02/2,1-(0.02/2), df=76))
qt(c(0.02/2, 1-(0.02/2)), df=76))
qt(c(0.02/2, 1-(0.02/2)), df=76)
(0.669-0.6)/0.024
1-(0.05/2)
2*pt(abs(2.875), df=58,lower.tail = FALSE)
7.810 + (0.669*300)
data <- data.frame(x1=c(1,2,3,4,5), x2=c("a","a","a","b","b"), y=c(45,78,89,188,129))
fit <- lm(y ~ x1+x2+x1:x2, data = data)
model.matrix(fit)
predict(fit, newdata=data.frame(x1=2,x2="b"), interval="prediction")
predict(fit, newdata=data.frame(x1=2,x2="b"))
?predict
getwd()
## da cancellare quando siete sicuri di dove è il file
dex1 <- read.csv("a01ex12_data.csv", header = TRUE)
dex1 <- read.csv("a01ex12_data.csv", header = TRUE)
getwd()
## da cancellare quando siete sicuri di dove è il file
dex1 <- read.csv("a01ex12_data.csv", header = TRUE)
getwd()
## da cancellare quando siete sicuri di dove è il file
dex1 <- read.csv("a01ex12_data.csv", header = TRUE)
dex1 <- read.csv("a01ex12_data.csv", header = TRUE)
dex1$Banks <- factor(dex1$Banks, ordered = TRUE, levels = c("Not","Bank"))
table(dex1$Banks)
getwd()
## da cancellare quando siete sicuri di dove è il file
# Per poter leggere i dati corretti - cambiare il valore nel numero di matricola qui sotto:
matricola <- 12345
# dex1 <- dget(paste0("https://raw.githubusercontent.com/ilapros/janExam/main/",matricola,"_a1ex1.txt"))
dex1 <- dget(paste0(your_path,matricola,"_a1ex1.txt"))
?poisson
250+90+40
