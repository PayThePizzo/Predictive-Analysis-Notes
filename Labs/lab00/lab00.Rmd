---
title: "Lab 0 - Revisione di R e predittori ottimali"
author: "Ilaria Prosdocimi"
date: "Semestre 1 - AA 2022/23"
output:
  html_document:
    fig_caption: yes
    theme: flatly #sandstone #spacelab #flatly
    highlight: pygments
    code_folding: show
    toc: TRUE
    toc_depth: 2
    number_sections: TRUE
    toc_float:
      smooth_scroll: FALSE
editor_options: 
  chunk_output_type: console
---

<!-- The default is to show the code - this can be changed in each chunk with the option  -->
<!-- class.source = "fold-hide" -->
<!-- To have the code hidden by default use in the yaml header -->
<!-- code_folding: hide  -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# R: rinfreschiamo un po' la memoria  

Andiamo a leggere un file esterno: dovremo aver premura di salvare il file in una posizione a noi nota nel nostro computer.  
Attenzione: RMarkdown esegue il codice prendendo la cartella dove è salvato il file .Rmd come la working directory. 
Si deve quindi indicare ad R la posizione del file o in maniera "assoluta" o in maniera relativa. 
Per controllare quale è la cartella dove stiamo al momento lavorando si può usare il comando `getwd()`:

```{r}
getwd()
```

Andiamo a leggere un file che contiene informazioni sul prezzo degli affitti nella città di Monaco insieme ad altre caratteristiche degli immobili in affitto. 
Il file è disponibile su Moodle ed è reso disponibile sul [sito](https://www.uni-goettingen.de/de/551625.html) del libro *Regression* di Fahrmeir et al (un ottimo libro che copre aspetti avanzati di regressione lineare e non lineare)

```{r}
mrents <- read.table("../data/rent99.raw", header = TRUE)
## rent: net rent per month (euros)
## rentsqm: net rent per month  per square meter (euros)
## area Living area square meters)
## year: year of construction
## location: as judged by an expert coded as 1=average location; 2: good location; 3= top location 
## bath: quality of the bathroom 0: standard; 1: premium
## kitchen: quality of the kitchen 0: standard; 1: premium
## cheating: presence of central heating 0: without; 1: with
## district: district in Munich
```

Usiamo questo dataset per rivedere alcuni comandi di R: 


```{r}
summary(mrents)
head(mrents)
```

La principale variabile di interesse è la variabile `rent`: si può visualizzare la distribuzione della variabile (che è continua) facendone  un istogramma: 

```{r}
hist(mrents$rent, xlab = "Rent")
```

Notiamo come la variabile sia abbastanza asimmetrica con una coda abbastanza lunga a destra. 

Possiamo calcolare (e visualizzare su un grafico) alcune caratteristiche della variabile: 

```{r}
mean(mrents$rent)
median(mrents$rent)
hist(mrents$rent, xlab = "Rent")
abline(v=mean(mrents$rent), col = 2, lwd =2)
abline(v=median(mrents$rent), col = 4, lwd =2)
legend("topright", bty = "n", col = c(2,4),lwd = 2,
       legend = c("mean","median"))
```

Per visualizzare invece le caratteristiche di variabili categoriali possiamo usare dei barplot: 

```{r}
par(mfrow=c(1,2))
barplot(table(mrents$kitchen)) 
barplot(table(mrents$cheating))
```

La maggior parte delle proprietà (`r table(mrents$kitchen)[1]` su `r length(mrents$kitchen)`) ha una cucina *standard*. Il `r signif(100*table(mrents$kitchen)[1]/length(mrents$kitchen),3)`% delle proprietà è fornito di riscaldamento centrale. 

Ora indagare quali siano i fattori che influenzano il prezzo di affitto di una proprietà. Per esempio si possono confrontare alcune caratteristiche degli affitti per diversi tipi di cucina: 

```{r}
summary(mrents$rent)
summary(mrents$rent[mrents$kitchen == 0])
summary(mrents$rent[mrents$kitchen == 1])
```

Usando dei boxplot si possono confrontare visualmente gli affitti in proprietà con cucine o bagni standard e premium: 

```{r}
par(mfrow=c(1,2))
boxplot(rent~kitchen, data = mrents)
boxplot(rent~bath, data = mrents)
```

Le proprietà con cucina o bagno *premium* tendono ad avere affitti più alti. 

Possiamo migliorare la leggibilità di questi grafici notando che sebbene `kitchen` sia codificata come variabile numerica nel dataset, essa sia in realtà una variabile categoriale: 

```{r}
# col2rgb("darkred")/255; col2rgb("dodgerblue")/255
mrents$kitchen_level <- factor(mrents$kitchen, labels = c("Standard","Premium"))
boxplot(rent~kitchen_level, data = mrents, col = c(rgb(0.45,0,0,0.4),rgb(0.118,0.565,1,0.4)),
        border= c("darkred","dodgerblue"))
```

Qual è invece l'effetto della `location`? 

```{r}
boxplot(rent~location, data = mrents, 
        col = c(rgb(0.45,0,0,0.4),rgb(0.118,0.565,1,0.4),rgb(0.118,0.85,0,0.4)),
        border= c(rgb(0.45,0,0),rgb(0.118,0.565,1),rgb(0.118,0.85,0)))
```

I boxplots risultano utili per confrontare variabili continue per diversi livelli di variabili categoriali. Spesso però il nostro interesse è nella relazione tra due o più variabili continue. Per esempio potremmo voler indagare l'effetto che ha l'area di un immobile sul prezzo d'affitto. Per visualizzare questa relazione possiamo usare un grafico di dispersione: 

```{r}
plot(rent~area, data = mrents, pch =16, bty = "l",col="darkorange2")
title(main = "relazione tra area e affitto")
```


# Predittori ottimali e regressione

Prendiamo in considerazione il dataset `cars` già a disposizione in R: 

```{r}
data(cars)
```

Possiamo avere più dettagli sul dataset leggendo l'help-file a disposizione in R:


```{r,eval=FALSE}
help(cars)
```

Diamo un primo sguardo alle caratteristiche del file: 

```{r sumCars}
summary(cars)
```

Vediamo che il dataset è composto da due variabili numeriche: `speed` prende valori tra 4 (mph) and 25 (mph) e `dist` prende valori tra 2 and 120 ft. Abbiamo in totale `r nrow(cars)` osservazioni. 

Possiamo osservare la relazione tra le due variabili con un grafico di dispersione:

```{r plotCars, echo=TRUE}
plot(cars) # notice the axis labels 
```

<!-- This is a comment.  -->
<!-- Notice we could obtain a similar plot simply using  -->
<!-- plot(dist~speed,data=cars)  -->
<!-- or  -->
<!-- plot(cars$speed, cars$dist) -->

La relazione tra le due variabili è positiva: macchine che viaggiano a velocità più alte necessitano di più spazio per fermarsi. Il coefficiente di correlazione (di Pearson) è `r format(cor(cars$speed, cars$dist),digits = 2)`: un valore piuttosto alto. 

Vogliamo ora stimare una retta di regressione che spieghi `dist` (Y) in funzione di `speed` (X). Dobbiamo quindi assumere che la relazione tra $X$ e $Y$ sia lineare: $Y = b_0 + b_1 X$. 
Troveremo poi delle stime per $b_0$ e $b_1$ usando le osservazioni campionarie. 
Nello specifico stimeremo  $b_0$ e $b_1$ in modo che la somma dei quadrati tra i valori osservati ($y_i$) e i valori stimati ($\hat{y}_i$) sia la più piccola possibile. Desideriamo quindi minimizzare (in funzione di $b_0$ e $b_1$) la seguente quantità: 
\[SumSq(b_0,b_1) = \sum_{i=1}^n{ (y_i - (b_0 + b_1{x}_i))^2 }.\]

Per valori arbitrari di $b_0$ e $b_1$ si può osservare la retta specificata dai valori e calcolare il valore di $SumSq(b_0,b_1)$

```{r plotCarsWithLines, class.source = "fold-hide", echo=TRUE}
par(mfrow=c(1,2), bty = "l") ## see ?par
plot(cars, pch = 16, col = "grey60") 
b0_1 <- -16; b1_1 <- 3
abline(b0_1, b1_1, col = 3)
segments(cars$speed, y0 = cars$dist, 
         y1 = b0_1 + b1_1 * cars$speed, 
         lty = 2, col = 3)
title(main=paste("y =",b0_1,"+",b1_1,"x"))
plot(cars, pch = 16, col = "grey60") 
b0_2 <- -17; b1_2 <- 4
abline(b0_2, b1_2, col = 4)
segments(cars$speed, y0 = cars$dist, 
         y1 = b0_2 + b1_2 * cars$speed, 
         lty = 2, col = 4)
title(main=paste("y =",b0_2,"+",b1_2,"x"))
```

Scriviamo ora una funzione che calcoli $SumSq(b_0,b_1)$: 
```{r sumSqComp,class.source = "fold-show"}
computeSumSquares <- function(bs, y, x){
  observed <- y
  modelled <- bs[1] + bs[2] * x
  squares <- (observed - modelled)^2
  sum(squares)
}
computeSumSquares(c(b0_1, b1_1), y = cars$dist,  x = cars$speed)
computeSumSquares(c(b0_2, b1_2), y = cars$dist,  x = cars$speed)
computeSumSquares(c(b0_2, b1_2+0.2), y = cars$dist,  x = cars$speed)
computeSumSquares(c(b0_2+1, b1_2), y = cars$dist,  x = cars$speed)
```

Si noti come i dati dell campione $(x,y)$ non cambiano. 

Calcoliamo per esempio la funzione per una griglia di possibili valori di $b_0$ e $b_1$: 


```{r calcSumSq, echo=TRUE}
b0seq <- seq(-20,-5, length.out = 7)
b1seq <- seq(3.4,4.6,length.out = 9)
ssqseq <- matrix(NA, ncol = 9, nrow= 7)
for(i in 1:7){
  for(j  in 1:9){
    ssqseq[i,j] <- computeSumSquares(c(b0seq[i], b1seq[j]), y = cars$dist,  x = cars$speed)
  }
}
```

La funzione dipende da entrambi i parametri: possiamo fare diversi grafici in 2-D o usare `persp` per fare un grafico in 3D in R:

```{r}
par(mfrow=c(1,2))
plot(b0seq,ssqseq[,1], type = "l", ylim = range(ssqseq))
lines(b0seq,ssqseq[,3], col = 2)
lines(b0seq,ssqseq[,5], col = 3)
lines(b0seq,ssqseq[,7], col = 4)
lines(b0seq,ssqseq[,9], col = 5)
legend("topright", col=c(1,2,3,4,5), legend = paste("b1 =",b1seq[c(1,3,5,7,9)]), lty = 1)
plot(b1seq,ssqseq[1,], type = "l", ylim = range(ssqseq))
lines(b1seq,ssqseq[3,], col = 2)
lines(b1seq,ssqseq[5,], col = 3)
lines(b1seq,ssqseq[7,], col = 4)
legend("topright", col=c(1,2,3,4), legend = paste("b0 =",b0seq[c(1,3,5,7)]), lty = 1)
```



```{r plotSumSq, class.source = "fold-hide"}
# image(b0seq,b1seq,ssqseq)
par(mfrow=c(1,2))
persp(b0seq,b1seq,ssqseq, ticktype = "detailed")
persp(b1seq,b0seq,t(ssqseq), ticktype = "detailed")
# which(ssqseq == min(ssqseq), arr.ind = TRUE)
### one can find the b0,b1 values which minimise the sum of squares 
### using the optim function
# optim(par = c(-4,-18), fn = computeSumSquares, 
   # y = cars$dist, x = cars$speed, method = "BFGS")
## this does a numerical minimisation
## outside the scope here 
```

Desideriamo individuare il valori ($b_0$,$b_1$) che minimizzano SumSq($b_0$,$b_1$). Potremmo usare un ottimizzatone numerico, ma in questo caso è possible trovare una soluzione analitica al problema che risulta essere: 
\[\hat{\beta}_1 = \frac{c_{XY}}{s^2_{X}} =  r_{XY} \frac{s_{Y}}{s_{X}},\quad \mbox{and} \quad \hat{\beta}_0 = \overline{y}-\hat{\beta}_1 \overline{x}  \]

```{r byHandCalc}
rxy <- cor(cars$dist, cars$speed)
sx <- sd(cars$speed); sy <- sd(cars$dist)
mx <- mean(cars$speed)
my <- mean(cars$dist)
beta1_hat <- rxy*sy/sx
beta0_hat <- my - beta1_hat * mx
c(beta0_hat, beta1_hat)
```


Fissiamo $b_0 =$ `r beta0_hat` - e guardiamo come cambia la somma dei quadrati in funzione di $b_1$: 

```{r minimiseForBeta1}
b1seq <- seq(3,5,length.out = 25)
ssqseq <- vector(mode = "numeric",25)
for(i in 1:25){
    ssqseq[i] <- computeSumSquares(c(beta0_hat, b1seq[i]), y = cars$dist,  x = cars$speed)
}
plot(b1seq, ssqseq, type="l")
abline(v = beta1_hat, col = 2, lty = 2)
abline(h = computeSumSquares(c(beta0_hat,beta1_hat), 
    y = cars$dist,  x = cars$speed), col = 2, lty = 2)
```

In R tipicamente non faremmo questi conti passo passo, ma possiamo direttamente usare la funzione `lm` che stima modelli di regressione che minimizzano la somma dei quadrati:  

```{r lmCars, class.source = "fold-show", echo=TRUE}
# Italian keyboard: to do ~ press Alt+0126
lm(dist ~ speed, data = cars) 
```

Possiamo vedere quali sono i valori stimati per i coefficienti di regressione usando la funzione `coef`

```{r}
fit <- lm(dist ~ speed, data = cars) 
coef(fit)
```


La linea stimata (e mostrata in figura) è la retta che minimizza la somma dei quadrati:  

```{r plotCarsFitted, class.source = "fold-hide", echo=TRUE}
bsOptimal <- coef(fit)
computeSumSquares(bsOptimal,
    y = cars$dist, x = cars$speed)
plot(cars, pch = 16, col = "grey60", bty = "l") 
abline(bsOptimal, col = "dodgerblue", lwd = 2) 
## Try any other value of b0 or b1 
## you will never get a value lower than computeSumSquares(bsOptimal, y = cars$dist, x = cars$speed)
```

Possiamo infine ottenere molte informazioni sulla stima ottenuta usando la funzione `summary`, che, quando applicata ad un oggetto di classe `lm` fornisce come output molte informazioni sulla stima ottenuta:

```{r}
summary(fit)
```

Vedremo nel corso delle prossime lezioni più dettagli sui vari componenti dell'output. 

Possiamo però già notare come R ci fornisca (`Residual standard error`) la stima di $\sigma$ - la deviazione standard della variabile casuale $Y|X$: 
\[s_e^2 = \frac{1}{n}\sum_{i=1}^{n} (y_i - \hat{y}_i)\]

Per calcolare $\hat{y}_i$ possiamo valutare la funzione $\beta_0 + \beta_1 x_i$: 

```{r}
fitted_vals <- coef(fit)[1]+coef(fit)[2]*cars$speed
head(fitted_vals)
```

La stima di $\sigma$ quindi è: 

```{r}
sqrt(sum((cars$dist - fitted_vals)^2)/(length(cars$speed)-2))
```



