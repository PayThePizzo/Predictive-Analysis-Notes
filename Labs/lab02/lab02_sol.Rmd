---
title: "Lab 02 - Multiple Linear Regression"
output:
  html_document:
    theme: readable
    toc: yes
    code_folding: show
---


Il dataset che useremo riguarda dati di automobili - per poter usare il dataset rendiamo il dataset più approciabile con alcune manipolazioni:  

```{r, class.source = "fold-hide"}
# read the data
fl <- "http://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data"
autompg = read.table(fl, quote = "\"",
comment.char = "", stringsAsFactors = FALSE)
# give the dataframe headers
colnames(autompg) <- c("mpg", "cyl", "disp", "hp", "wt",
"acc", "year", "origin", "name")
# remove missing data, which is stored as "?"
autompg <-subset(autompg, autompg$hp != "?")
# remove the plymouth reliant, as it causes some issues
autompg <- subset(autompg, autompg$name != "plymouth reliant")
# give the dataset row names, based on the engine, year and name
rownames(autompg) <- paste(autompg$cyl, "cylinder",
autompg$year, autompg$name)
# remove the variable for name, as well as origin
autompg <- subset(autompg,
select = c("mpg", "cyl", "disp", "hp", "wt", "acc", "year"))
# change horsepower from character to numeric
autompg$hp <- as.numeric(autompg$hp)
# write.csv(autompg, "../data/autompg.csv", quote = FALSE)
```

Desideriamo per ora stimare come le miles per gallon `mpg` varino in funzione del peso `wt`  e dell'anno di produzione `year`. 


```{r dataplot}
par(mfrow=c(1,2), bty="l",pch=16)
plot(mpg~wt, data= autompg)
plot(mpg~year, data= autompg)
```


# Specificazione del modello 

Estendiamo il modello di regressione semplice permettendo che più di un predittore spieghi la variabilità di $Y$: 

In generale, il modello di regressione multipla è specificato come segue: 
\[
Y_i = \beta_0 + \beta_1 x_{i1} + \beta_2 x_{i2} + \epsilon_i, \qquad i = 1, 2, \ldots, n
\]
con $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$ (errori indipendenti). 

In forma matriciale questo corrisponde a

\[
\begin{bmatrix}
Y_1   \\
Y_2   \\
\vdots\\
Y_n   \\
\end{bmatrix}
=
\begin{bmatrix}
1      & x_{11}    & x_{12}    & \cdots & x_{1(p-1)} \\
1      & x_{21}    & x_{22}    & \cdots & x_{2(p-1)} \\
\vdots & \vdots    & \vdots    &  & \vdots \\
1      & x_{n1}    & x_{n2}    & \cdots & x_{n(p-1)} \\
\end{bmatrix}
\begin{bmatrix}
\beta_0 \\
\beta_1 \\
\beta_2 \\
\vdots \\
\beta_{p-1} \\
\end{bmatrix}
+
\begin{bmatrix}
\epsilon_1   \\
\epsilon_2   \\
\vdots\\
\epsilon_n   \\
\end{bmatrix}
= X \beta + \epsilon, 
\]

dove X è la matrice di disegno del modello e $\beta$ il vettore di coefficienti $(\beta_0, \beta_1, \ldots, \beta_{p-1})$. Nel nostro esempio abbiamo $p=2$  e possiamo scrivere il modello come segue: 
\[
\texttt{mpg}_i = \beta_0 + \beta_1 \texttt{wt}_{i} + \beta_2 \texttt{year}_{i} + \epsilon_i, \qquad i = 1, 2, \ldots, n
\]
con $\epsilon_i \sim \mathcal{N}(0, \sigma^2)$ (errori indipendenti). 

La matrice $X$ è quindi: 

\[ 
X = \begin{bmatrix}
1      & wt_{1}     & year_{1} \\
1      & wt_{2}     & year_{2} \\
\vdots & \vdots     & \vdots   \\
1      & wt_{n}    & year_{n} \\
\end{bmatrix}
\]

Per ottenere una stima dei coefficenti del modello utilizziamo la funzione `lm`: 

```{r, class.source = "fold-show"}
fit <- lm(mpg~wt+year, data = autompg)
```

```{r}
class(fit); names(fit)
```


`fit` è un oggetto di classe `lm` e possiamo usare le funzioni che abbiamo già utilizzato per il modello di regressione semplice (con alcuni accorgimenti in alcuni casi):  

```{r}
fit$coef; coef(fit)
head(fitted(fit))
head(residuals(fit))
```

# Inferenza per i parametri 

In particolare la funzione `summary` ci permette di fare una prima inferenza sui parametri: 

```{r}
summary(fit)
```

Vediamo da dove vengono questi numeri. 

Iniziamo dal creare la matrice di disegno $X$: 

```{r}
n <- nrow(autompg)
X <- cbind(rep(1,n), autompg$wt, autompg$year)
y <- autompg$mpg
```

La stima puntuale di $\beta$ viene derivata con: 
\[\hat{\beta} = (X^T X) ^{-1} X^T y.\]

```{r}
(beta_hat <- as.vector(solve(t(X) %*% X) %*% t(X) %*% y))
coef(fit)
```

[Bonus question:  i valori stimati corrispondono ai valori che minimizzano i quadrati dei residui? Si scriva una funzione che valuti il valore dell'errore quadratico medio campionario per diversi valori di $\boldsymbol{\beta}$ e si verifichi se il valori stimati minimizzano l'errore quadratico medio.]

Dato che assumiamo che $\varepsilon$ segua una distribuzione normale, di conseguenza assumiamo anche $Y|X$ segua una distribuzione normale e che le osservazioni $(y_i, \ldots, y_n)$ siano una realizzazione della variabile casuale: $(Y|X=x) \sim N(X \beta, \sigma^2 I_n)$ e ne consegue che $\hat{\beta}$ segua una normale con media e varianza:

\[E[\hat{\beta}] = \beta \quad \text{and} \quad V[\hat{\beta}] = \sigma^2 (X^T X)^{-1}  \]

Dato che $\sigma^2$ non è noto viene stimato con: 
\[s^2_e = \frac{\sum_{i=1}^{n}(y_i - \hat{y}_i)^2}{n-p} = \frac{\sum_{i=1}^{n}e^T e }{n-p} \]
dove $e$ è il vettore degli errori del modello. 

```{r}
(est_sigma <- sqrt(sum(fit$residuals^2)/(n-length(fit$coef))))
summary(fit)$sigma
(se_beta_hat <- as.vector(est_sigma * sqrt(diag(solve(t(X) %*% X)))))
summary(fit)$coef[,2]
```

Possiamo derivare anche l'intera matrice di varianza covarianza di $\beta$: 

```{r}
(est_sigma^2) * (solve(t(X) %*% X))
vcov(fit)
```

I valori della covarianza sono a volte difficili da interpretare e può essere comodo derivare la matrice di correlazione tramite la funzione `cov2cor` per valutare la correlazione tra la stima dei parametri: 

```{r}
cov2cor(vcov(fit))
S <- diag(sqrt(diag(vcov(fit))))
S %*% cov2cor(vcov(fit)) %*% S
```

Desideriamo  avere delle correlazioni piccole tra le stime, ma su questo punto torniamo dopo. Per ora ci concentriamo sul capire come sono costruite le ultime due colonne dell'output della tabella dei coefficenti in `summary(fit)$coef`. Queste colonne hanno a che fare con i due sistemi di verifica di ipotesi: 
\[H_0: \beta_1 = 0 \quad VS \quad H_1: \beta_1 \neq 0 \]
\[H_0: \beta_2 = 0 \quad VS \quad H_1: \beta_2 \neq 0 \]
la terza colonna mostra il valore del test, la quarta colonna il valore del p-value. Questi sono test relativi ai singoli valori di dei $\beta_j$ e danno una prima indicazione dell'evidenza che il coefficiente relativo ad una variabile $x_j$ possa essere considerato pari a zero e in maniera indiretta un'indicazione dell'opportunità di mantenere la variable $x_j$ nel modello. Si può considerare comunque utile mantenere una variabile nel modello anche se il test formale $H_0: \beta_j = 0$ non può essere  rifiutato ad un determinato livello di significatività: forse questa variabile rappresenta qualcosa che desideriamo sia rappresentato nel modello. 

La statistica test si deriva con: 
\[\frac{\hat{\beta}_j - 0}{se(\hat{\beta}_j)} \]

```{r tvals}
beta_hat/se_beta_hat
summary(fit)$coef[,3]
```

e il valore del p-value con 


```{r}
(TS <- (beta_hat[3]-0)/se_beta_hat[3])
2*pt(abs(TS),n-length(beta_hat), lower.tail = FALSE)
summary(fit)$coef[,4]
``` 

Inoltre si possono derivare intervalli di confidenza con la funzione `confint` (o calcolando manualmente): 

```{r cis}
### 98% confidence intervals 
cbind(beta_hat+qt(0.01, n-length(fit$coefficients))*se_beta_hat,
      beta_hat+qt(0.99, n-length(fit$coefficients))*se_beta_hat)
confint(fit, level = .98)
```

Infine possiamo derivare dei test per qualunque valore arbitrario del coefficiente. Ad esempio possiamo voler quantificare l'evidenza contro l'ipotesi nulla $\beta_2 = \beta^*$, cioè costruire un test per il sistema di verifica di ipotesi: 
\[H_0: \beta_2 = \beta^* \quad VS \quad \beta_2 \neq \beta^* \]

Prendiamo ad esempio $\beta^* = 0.86$: 

```{r}
(TS <- (beta_hat[3]-0.86)/se_beta_hat[3])
2*pt(abs(TS),n-length(beta_hat), lower.tail = FALSE)
## reject at 5%, do not reject at 2%
### one can also use the car::linearHypothesis function
```

In realtà nel momento in cui costruiamo gli intervalli di confidenza abbiamo anche informazioni sui valori $\beta^*$ per cui il test $H_0: \beta_j =  \beta^*$ saranno rifiutati o meno al livello di significatività $\alpha$: 

```{r}
confint(fit, level = 0.98) 
## livello di confidenza: 98%
cbind(beta_hat + qt(0.01, df=387) * se_beta_hat,
      beta_hat + qt(0.99, df=387) * se_beta_hat)
## test per H_0: \beta_2 = 0.64
(TS <- (beta_hat[3]-0.64)/se_beta_hat[3])
2*pt(abs(TS),n-length(beta_hat), lower.tail = FALSE) # reject at 2% siignificance
## test per H_0: \beta_2 = 0.65
(TS <- (beta_hat[3]-0.65)/se_beta_hat[3])
2*pt(abs(TS),n-length(beta_hat), lower.tail = FALSE) # can not reject at 2% siignificance
```

Infine usiamo la funzione `confidenceEllipse` nel pacchetto `car` per disegnare intervalli di confidenza bivariati, per esempio per $(\beta_0, \beta_1)$ e $(\beta_0, \beta_2)$:

```{r}
par(bty = "l", mfrow=c(1,2))
car::confidenceEllipse(fit, which.coef=c(1,2), vcov.=vcov(fit), grid = FALSE)
car::confidenceEllipse(fit, which.coef=c(1,3), vcov.=vcov(fit), grid = FALSE)
```

Come viene costruita l'ellissi? La procedura è spiegata estesamente nella Lecture 18 di Cosma Shalizi's [lectures](https://www.stat.cmu.edu/~cshalizi/mreg/15/lectures). In generale dobbiamo usare il fatto che la distribuzione chi-quadro è derivata come il quadrato di una normale  e che la somma di chi-quadro segua una distribuzione chi-quadro. Indichiamo con  $\mathbf{\beta}_q$ il vettore dei parametri per cui vogliamo costruire l'intervallo di confidenza, e con $\mathbf{\Sigma}_q$ la corrispondente matrice di varianza-covarianza. La regione di confidenza per $\mathbf{\beta}_q$ viene trovata come segue: 
\begin{equation*}
(\widehat{\mathbf{\beta}}_q - \mathbf{\beta}_q)^T \mathbf{\Sigma}^{-1}_q
(\widehat{\mathbf{\beta}}_q - \mathbf{\beta}_q) \leq \chi^2_q(1-\alpha)
\end{equation*}
I dettagli della teoria sottostante questa derivazione non sono parte del corso.. 


# Inferenza sulla funzione stimata 

Per un dato valore di $x_i$, il valore di $y$ stimato è: 

\[\hat{y}_i = \hat{\beta}_0 + \hat{\beta}_1 x_{1i} + \ldots + \hat{\beta}_{(p-1)} x_{(p-1)i}  = X \hat{\beta} = X  (X^T X) ^{-1} X^T y.\]
La matrice $H = X  (X^T X) ^{-1} X^T$ viene detta la hat matrix, perché è la matrice che permette di trasformare i calori osservati $y_i$ nei corrispondenti valori stimati (hat y) $\hat{y}_i$ (`y_hat`). 

```{r estiamtingY}
H <- X  %*% solve(t(X) %*% X) %*% t(X)
y_hat <- as.vector(H %*% y)
head(y_hat); head(as.vector(fit$fitted.values))
```

La funzione `predict` ci permette di estrarre gli intervalli di confidenza e predizione: 

```{r predictFun}
nd <- data.frame(wt = c(1650, 3000, 5000), year = c(72, 75, 82))
(cint <- predict(fit, nd, interval = "conf"))
## da dove vengono questi numeri?
x0 <- cbind(rep(1,3), c(1650, 3000, 5000),c(72, 75, 82)) 
se_cx0 <- est_sigma * sqrt(diag(x0 %*% solve(t(X) %*% X) %*% t(x0)))
cbind(x0 %*% beta_hat + qt(0.025, n-length(beta_hat)) * se_cx0,
      x0 %*% beta_hat + qt(0.975, n-length(beta_hat)) * se_cx0)
(pint <- predict(fit, nd, interval = "pred"))
## da dove vengono questi numeri?
se_px0 <- est_sigma * sqrt(1+diag(x0 %*% solve(t(X) %*% X) %*% t(x0)))
cbind(x0 %*% beta_hat + qt(0.025, n-length(beta_hat)) * se_px0,
      x0 %*% beta_hat + qt(0.975, n-length(beta_hat)) * se_px0)
rm(se_px0, se_cx0)
```


Entrambi gli intervalli sono centrati sul valore stimato puntuale, ma gli intervalli di predizione sono sempre più ampi. 

```{r}
cint[,3] - cint[,2]
pint[,3] - pint[,2]
```

Notiamo anche che uno degli intervalli di confidenza è molto più largo degli altri: perché?

```{r}
plot(autompg$wt, autompg$year,pch=16,col="dodgerblue2")
points(nd, pch =4, col="orange",lwd=3)
points(mean(autompg$wt), mean(autompg$year), pch = 15, col="red",cex=1.3)
```

C'è più incertezza nella stima di punti distanti dal valore $(\bar{x}_1, \bar{x}_2)$ e in generale per i punti lontani dai valori osservati nel dataset. 


# Visualizzare la stima

Come possiamo visualizzare i valori stimati di $y_i$? Facciamo un primo tentativo:   

```{r fittedPlotWrong}
par(mfrow=c(1,2), bty="l",pch=16)
plot(mpg~wt, data= autompg,col="grey50")
points(autompg$wt, y_hat, col = 4, pch = 15)
plot(mpg~year, data= autompg,col="grey50")
points(autompg$year, y_hat, col = 2, pch = 15)
```

Non esattamente chiaro... 

I valori stimati dipendono dalla combinazione dei valori osservati di `wt` e `year`, quindi la relazione stimata tra una variabile esplicativa e $Y$ che vediamo è "sporcata" dalla dipendenza con l'altra variabile. Non possiamo più usare semplicemente `abline` per fare un grafico che mostri la relazione: dobbiamo in qualche modo "fissare" il valore dell'altra variabile. Questo si può fare usando la funzione `predict` (o approcci simili). Possiamo quindi mostrare la retta che mostri la relazione tra `wt` e `mpg` *tendendo fisso il valore di `year`* e viceversa. Similmente, possiamo mostrare come `year` impatti `mpg` per determinati valori di `wt`:  

```{r fittedPlot}
par(mfrow=c(1,2), bty="l",pch=16,col="grey70")
plot(mpg~wt, data= autompg)
nd <- data.frame(wt = seq(1500, 5200, length.out = 100), year = mean(autompg$year))
lines(nd$wt, predict(fit, nd), lwd=2,col=4)
plot(mpg~year, data= autompg)
## an "X" matrix but with one column with fixed values 
Xfix <- cbind(rep(1,n),rep(min(autompg$wt)),autompg$year)
lines(autompg$year, Xfix %*% coef(fit), lwd = 2 , col = 2)
Xfix <- cbind(rep(1,n),rep(median(autompg$wt)),autompg$year)
lines(autompg$year, Xfix %*% coef(fit), lwd = 2 , col = 5)
```

