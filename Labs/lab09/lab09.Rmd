---
title: "Lab 09 - more about GLMs"
output: 
  html_document: 
    toc: yes
---


# Model selection per i GLMs - Binomial 

I dati nel file `SAheart.csv` sono stati raccolti in uno studio osservazionale retrospettivo su un campione di uomini residenti in una zona ad alto rischio di malattie cardiache a Città del Capo in Sud Africa. La variabile `chd` (coronary heart disease), che useremo come variabile risposta, è una variabile binaria (codificata con valori 0/1) che indica se un individuo presenta malattie alle coronarie. Le altre variabili presenti nel dataset sono: 

* sbp: systolic blood pressure
* tobacco: cumulative tobacco (kg)
* ldl: low densiity lipoprotein cholesterol
* adiposity
* famhist: family history of heart disease (Present, Absent)
* typea: type-A behavior
* obesity
* alcohol: current alcohol consumption
* age: age at onset

[Qui](https://hastie.su.domains/ElemStatLearn/) potete trovare più informazioni sul dataset. 



```{r, eval=TRUE}
SAheart <- read.table("SAheart.csv",sep=",",head=TRUE)
```

Desideriamo costruire un modello che predica la probabilità di avere una malattia alle coronarie dati i valori delle altre caratteristiche. Possiamo fare una prima analisi esplorativa per vedere le caratteristiche delle diverse variabili esplicative nei gruppi di persone malate e non malate (escludiamo dai grafici :  

```{r}
par(mfrow=c(2,2))
for(j in 1:4) plot(jitter(SAheart$chd, amount = 0.2)~SAheart[,j], main = names(SAheart)[j])
```
Per alcune di queste variabili continue sembra esserci un legame.

```{r}
par(mfrow=c(2,2))
for(j in 6:9) plot(jitter(SAheart$chd, amount = 0.2)~SAheart[,j], main = names(SAheart)[j])
```
Quando abbiamo una variabile dicotomica come risposta ed una variabile categoriale come predittore, conviene fare una tabella di contingenza e/o un `mosaicplot`

Per `famhist`, che è una variabile categoriale, possiamo utilizzare un cosiddetto mosaicplot: 

```{r}
table(SAheart$famhist, SAheart$chd)
mosaicplot(table(SAheart$famhist, SAheart$chd))
```
Vediamo che vi e' una maggiore numerosita' di `absent` (data dalla larghezza della colonna) rispetto a `present`. Inoltre, sembra esserci un' associazione tra avere problemi alle coronarie ed avere una storia familiare dal momento che i valori della diagonale sono piu' "pesanti" che i valori fuori dalla diagonale.

## First attempt

Iniziamo con un primo modello che utilizza `ldl` come predittore e `chd` come variabile risposta.

```{r}
chd_mod_ldl <- glm(chd ~ ldl, family = binomial, data = SAheart)
summary(chd_mod_ldl)
```
Come abbiamo intuito, al crescere dei valori del colesterolo, cresce il rischio di avere una malattia alle coronarie.
Purtroppo pero', non sappiamo interpretare gli `0.27466` punti di crescita, per questo ci serve utilizzare un grafico o guardare dei punti di interesse.

```{r}
par(mfrow=c(1,1))

plot(SAheart$ldl, jitter(SAheart$chd, amount = 0.14), pch = 16)

lines(sort(SAheart$ldl), 
      predict(chd_mod_ldl, newdata = data.frame(ldl = sort(SAheart$ldl)),
             type = "response"), col = "red")
```
E' interessante vedere che non si raggiungono mai gli estremi della probabilita' (ne' 0, ne' 1) e che la crescita, sebbene sia positiva, non e' lineare nella scala della probabilita'. 

* L'effetto di passare da 2 a 3, non e' lo stesso di passare da 8 a 9;
* Lo e' solo nella scala della `log-odds`

### Intervalli di confidenza

Se vogliamo verificare l'intervallo di confidenza per il valore, possiamo usare:
```{r}
confint.default(chd_mod_ldl, level = 0.99, parm = "ldl")
```
E' fortemente significativo, sebbene piccolo e' distante da `0`. L'intervallo e' costruito a partire dal fatto che l'aprossimazione di una normale (che deriva dal fatto che il modello e' approssimato tramite massima verosimiglianza).

* Per costruire l'intervallo si usa il quantile della normale, quindi e' simmetrico.

## Second Attempt

Proviamo ora ad utilizzare un secondo modello, che include tutti i predittori in forma additiva (senza interazioni)

```{r}
chd_mod_additive <- glm(chd ~ ., family = binomial, data = SAheart)
summary(chd_mod_additive)
```

Otteniamo una devianza molto piu' bassa di quella nulla, possiamo dedurre che il modello sia significativo. Tanti predittori singoli non sono significativi, dunque ci poniamo l'obiettivo di trovare un modello significativo e parsimonioso.

Confrontiamo le devianze dei due modelli

### LRT

```{r}
anova(chd_mod_ldl, chd_mod_additive, test = "LRT")
```

Il modello additivo e' significativamente diverso e ci dovrebbe, percio', essere un modello intermedio che sia significativo. 


### Stepwise Selection

Utilizziamo una selezione del modello tramite *Stepwise selection* basata su *AIC*

```{r}
# Backward
chd_mod_select <- step(chd_mod_additive, k = 2) # use AIC

# Forward
step(chd_mod_ldl, direction = "forward", 
     scope = list(lower = chd_mod_ldl, upper = chd_mod_additive))

# Both
step(chd_mod_ldl, direction = "both", 
     scope = list(lower = chd_mod_ldl, upper = chd_mod_additive))

```

Togliendo un elemento alla volta, la selezione arriva ad un modello che ha `AIC=487.69` con la formula `chd ~ ldl + age + famhist + tobacco + typea`

```{r}
chd_mod_select
```
Vediamo quindi che vi sono delle relazioni positive per quasi tutti i predittori.

* In particolare quando `famhist` e' `present`, il coefficiente e' molto positivo. Stiamo stimando due predittori lineari paralleli tra loro (perche e' una variabile categorica). 


### LRT

```{r}
anova(chd_mod_ldl, chd_mod_select, test = "LRT")
```
Troviamo un miglioramento significativo rispetto al modello piu' semplice

```{r}
anova(chd_mod_additive, chd_mod_select, test = "LRT")
```
Purtroppo rispetto al modello adittivo, non vi e' grande evidenza statistica di miglioramento.

### Interpretazione ed Incertezza
Come nei MLR, l'interpretazione dei predittori e' la seguente: il valore (positivo o negativo) e' l'effetto che ha il predittore `beta` sul log-odd-ratio, assumendo che tutti gli altri predittori abbiano valori fissi. Infatti, per visualizzare questi effetti tramite grafici, si devono prima fissare i valori dei predittori.


```{r}
plot(SAheart$ldl, jitter(SAheart$chd, amount = 0.14), pch = 16)

# "pure" ldl effect
lines(sort(SAheart$ldl), 
      predict(chd_mod_ldl, newdata = data.frame(ldl = sort(SAheart$ldl)),
             type = "response"), col = "red")

# Fix the values
nd <- data.frame(ldl = seq(0,16), age = median(SAheart$age), 
                 tobacco = median(SAheart$tobacco), 
                 famhist = "Absent", typea = median(SAheart$typea))

# ldl effect, given that all the predictors have median values
lines(sort(nd$ldl), 
      predict(chd_mod_select, newdata = nd,
             type = "response"), col = "orange")

# ---
# Uncertainty estimation

# fit, se.fit
linpred <- predict(chd_mod_select, newdata = nd,
             type = "link", se.fit = TRUE)

# confidence intervals for the linear predictor
# upper and lower bound
cint <- cbind(linpred$fit - qnorm(.995) * linpred$se.fit,
              linpred$fit + qnorm(.995) * linpred$se.fit)

# two columns of values between 0 and 1
cint_response <-  binomial()$linkinv(
    cbind(linpred$fit - qnorm(.995) * linpred$se.fit, 
          linpred$fit + qnorm(.995) * linpred$se.fit))

lines(sort(nd$ldl), cint_response[,1], lty = 2, col = "purple")
lines(sort(nd$ldl), cint_response[,2], lty = 2, col = "purple")
  
```
L'effetto del colesterolo, a valori fissati, (linea arancione non tratteggiata) e' meno forte rispetto all'effetto "puro" dello stesso (linea rossa). Questo accade probabilmente perche' la linea rossa descrive le persone con il colesterolo alto e che hanno un'eta' maggiore. Come nei modelli lineare, con cosi' tante variabili e' difficile spiegare esattamente come influisce.

Per quanto riguarda l'incertezza dei parametri, e' facilmente reperibile una volta ottenuta l'incertezza della stima. E' molto piu' semplice nei MLR, dove le trasformazioni sono lineari, mentre qui le linee non tratteggiate sono trasformazioni non-lineari (si passa attraverso la link function).

### Intervalli approssimati

Quello che si fa e' costruire degli intervalli di confidenza a partire da

$$\hat{\eta} = X\hat{\beta}\rightarrow \hat{V}(\hat{\eta}) = X\hat{V}(\hat{\beta})X^{T}$$
Per $\eta_{i}$ il livello di confidenza $1-\alpha$

$$\left(\hat{\eta}_{i} + z_{\alpha/2} \left( \hat{V}(\hat{\eta})\right)_{ii}, \hat{\eta}_{i} + z_{1-\alpha/2} \left( \hat{V}(\hat{\eta})\right)_{ii} \right)$$
Per $\mu_{i}$ il livello di confidenza si ottiene invece:

$$\left( g^{-1} \left(\hat{\eta}_{i} + z_{\alpha/2} \left( \hat{V}(\hat{\eta})\right)_{ii} \right), g^{-1}\left( \hat{\eta}_{i} + z_{1-\alpha/2} \left( \hat{V}(\hat{\eta})\right)_{ii} \right) \right) $$
Sebbene siano approssimati, cio' ci assicura che gli intervalli di confidenza appartengano ad un range di valori per cui $\mu$ puo' essere definito. Cio' e' possibile grazie alla funzione legame.

### Predizione

Per quanto riguarda gli intervalli di predizione, nei GLM non si possono fare intervalli di predizione, questo e' dato dal fatto che i valori stimati coinvolgevano la varianza ma qui non abbiamo la varianza del modello. In alternativa possiamo simularli tramite `simulate` che simula dati da un modello stimato per poterci aiutare a vedere cosa potrebbe succedere su un dataset.

---

# Model selection per GLMs - Poisson 

Ci concentriamo ora sul dataset `hcrabs` in cui la variabile di interesse è il numero di satelliti attorno ad un granchio femmina. Desideriamo individuare i predittori che possono risultare utili nello spiegare la variabilità della variabile risposta. Innanzitutto leggiamo il dataset ed esploriamo le relazioni tra predittori e risposta: 


```{r}
hcrabs <- read.csv("hcrabs.csv", header = TRUE)
plot(hcrabs)
```


`Spine` e `Col` sono dei fattori ordinati: 

```{r}
# Categorical variables
hcrabs$Spine <- factor(hcrabs$Spine, levels = c("NoneOK", "OneOK", "BothOK"))
hcrabs$Col <- factor(hcrabs$Col, levels = c("LM", "M", "DM", "D"))
```

`Sat` (la variabile risposta) sembra essere legata a `Width` e `Wt`, le quali però sono anche legate tra loro. Le altre variabili nel dataset sono variabili categoriali Inoltre ci sono alcune variabili categoriali per cui lo scatterplot non facilita la comprensione delle relazioni tra i predittori ma che sembrano avere forse qualche effetto su `Sat`: 

```{r}
par(mfrow=c(1,2))
plot(Sat~Col, data =hcrabs)
plot(Sat~Spine, data =hcrabs)
```
 Persistono problemi di multicollinearita', ma non andiamo in fondo alla questione
 poiche' l'obbiettivo del file e' un altro.

## Full additive model vs Simplest model

Iniziamo la procedura di selezione del modello specificando i due modelli additivi più semplice e più complesso possibile: utilizzeremo poi la funzione `step` per verificare se esiste un modello con complessità intermedia tra i due che spieghi sufficientemente bene i dati. 

```{r}
model0<-glm(Sat~1, family=poisson(link=log),data=hcrabs)
modelFull<-glm(Sat~., family=poisson(link=log),data=hcrabs)
anova(model0, modelFull, test = "LRT") ## at least some variables are significant
```
Il modello, sebbene complicato, e' significativo. Proviamo ad utilizzare la stepwise
selection

## Stepwise Selection

Come criterio di valutazione della bontà di adattamento possiamo usare AIC or BIC (quindi prendiamo $k=log(n)$ nella penalizzazione): 

```{r}
selAIC <-  step(model0, direction = "forward", scope = list(lower = model0, upper = modelFull))
summary(selAIC)
```
Questo modello e' interesante poiche' si ha una variabile continua ed una categoriale. Per quanto riguarda la categoriale, e' come se stimassimo 4 curve "parallele" sulla scala dei predittori.

* Il modello ha un coefficiente per ogni categoria,

 E' opportuno ricordare che la stepwise selection confronta solo modelli additivi. 

In alternativa possiamo decidere di analizzare le eventuali presenze di interazioni. Cio' comporta avere 4 curve con forme diverse.

```{r}
modelInteract <- glm(Sat~Wt*Col, family=poisson(link=log),data=hcrabs)
summary(modelInteract)
```
Analizziamo i risultati

* E' interessante che la stima di `Wt` sia negativa, poiche' dal grafico dei predittori dovrebbe risultare positivo. E' interpretato come l'effetto del peso pe la categoria `lM` (di colore). 
* Vediamo che il peso ha un effetto positivo per il resto dei granchi.

### AIC
E' possibile utilizzare AIC dal momento che abbiamo modelli annidati

```{r}
AIC(selAIC, modelInteract)
```
AIC determina che il modello con le interazioni e' il migliore tra i due.

### LRT

```{r}
anova(selAIC, modelInteract, test = "LRT")
```
Il modello con le interazioni risulta ad essere migliore, sebbene il livello di significativita' non sia cosi' statisticamente importante.


```{r}
hcrabs <- hcrabs[order(hcrabs$Wt),]
plot(hcrabs$Wt, hcrabs$Sat, col = as.numeric(hcrabs$Col), pch = 16)
# 4 different curves
lines(hcrabs$Wt[hcrabs$Col =="LM"], 
       predict(selAIC, type = "response")[hcrabs$Col =="LM"], col = 1, lwd = 2)
lines(hcrabs$Wt[hcrabs$Col =="M"], 
       predict(selAIC, type = "response")[hcrabs$Col =="M"], col = 2, lwd = 2)
lines(hcrabs$Wt[hcrabs$Col =="DM"], 
       predict(selAIC, type = "response")[hcrabs$Col =="DM"], col = 3, lwd = 2)
lines(hcrabs$Wt[hcrabs$Col =="D"], 
       predict(selAIC, type = "response")[hcrabs$Col =="D"], col = 4, lwd = 2)
```
Dal risultato vediamo che non ci sono punti neri (granchi `lM`), la stima per questi punti avra' ovviamente una grande varianza, sebbene sia comunque contenuta perche' non vengono stimate separatamente le categorie riguardo al colore.

Per quanto riguarda le curve, la linea azzurra e verde sono praticamente sovrapposte e tendono ad oscurarsi, percio' e' opinabile collassare le due categoria in una singola. Le tre curve sono proporzionali. 

Vediamo lo stesso con il modello che include le interazioni.

```{r}
plot(hcrabs$Wt, hcrabs$Sat, col = as.numeric(hcrabs$Col), pch = 16)
lines(hcrabs$Wt[hcrabs$Col =="LM"], 
       predict(modelInteract, type = "response")[hcrabs$Col =="LM"], col = 1, lwd = 2)
lines(hcrabs$Wt[hcrabs$Col =="M"], 
       predict(modelInteract, type = "response")[hcrabs$Col =="M"], col = 2, lwd = 2)
lines(hcrabs$Wt[hcrabs$Col =="DM"], 
       predict(modelInteract, type = "response")[hcrabs$Col =="DM"], col = 3, lwd = 2)
lines(hcrabs$Wt[hcrabs$Col =="D"], 
       predict(modelInteract, type = "response")[hcrabs$Col =="D"], col = 4, lwd = 2)
```

Le curve stimate ci confermano gli effetti del peso per ogni categoria, visti precedentemente nel summary.

### Intervallo di confidenza

Bisognerebbe andare a confrontare, tramite IC sulla scala della risposta, per vedere se effettivamente l'effetto che sembra negativo di `Wt` per la linea nera, abbia senso.

Intevallo di confidenza per un granchio di peso 3000 nelle 4 categorie di colore: 

```{r}
nd <- data.frame(Wt = 3000, Col = c("LM","M","D","DM"))
cint <- predict(modelInteract, newdata = nd, type = "link", se.fit = TRUE)
exp(cbind(cint$fit - qnorm(.995)*cint$se.fit, cint$fit + qnorm(.995)*cint$se.fit)) 
```

Questo e' un IC sulla scala della risposta (valore atteso di Y).



