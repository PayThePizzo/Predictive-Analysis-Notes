---
title: "Lab 09 - more about GLMs"
output: 
  html_document: 
    toc: yes
---


# Model selection per i GLMs - Binomial 

I dati nel file `SAheart.csv` sono stati raccolti in uno studio osservazionale retrospettivo su un campione di uomini residenti in una zona ad alto rischio di malattie cardiache a Città del Capo in Sud Africa. La variabile `chd` (coronary heart disease), che useremo come variabile risposta, è una variabile binaria (codifcata con valori 0/1) che indica se un individuo presenta malattie alle coronarie. Le altre variabili presenti nel dataset sono: 

* sbp: systolic blood pressure
* tobacco: cumulative tobacco (kg)
* ldl: low densiity lipoprotein cholesterol
* adiposity
* famhist: family history of heart disease (Present, Absent)
* typea: type-A behavior
* obesity
* alcohol: current alcohol consumption
* age: age at onset

[Qui](https://hastie.su.domains/ElemStatLearn/) potete trovare più informazioni sul dataset. 



```{r, eval=TRUE}
SAheart <- read.table("SAheart.csv",sep=",",head=TRUE)
```

Desideriamo costruire un modello che predica la probabilità di avere una malattia alle coronarie dati i valori delle altre caratteristiche. Possiamo fare una prima analisi esplorativa per vedere le caratteristiche delle diverse variabili esplicative nei gruppi di persone malate e non malate (escludiamo dai grafici le variabili categoriali):  

```{r}
par(mfrow=c(2,2))
for(j in 1:4) plot(jitter(SAheart$chd, amount = 0.2)~SAheart[,j], main = names(SAheart)[j])
```

```{r}
par(mfrow=c(2,2))
for(j in 6:9) plot(jitter(SAheart$chd, amount = 0.2)~SAheart[,j], main = names(SAheart)[j])
```


Per `famhist`, che è una variabile categoriale, possiamo utilizzare un cosiddetto mosaicplot: 


```{r}
table(SAheart$famhist, SAheart$chd)
mosaicplot(table(SAheart$famhist, SAheart$chd))
```

Possiamo costruire un primo modello predittivo utilizzando `ldl`, i livelli di colesterolo, come variabile esplicativa:

```{r}
par(mfrow=c(1,1))
chd_mod_ldl <- glm(chd ~ ldl, data = SAheart, family = binomial)
summary(chd_mod_ldl)
plot(jitter(chd, factor = 0.1) ~ ldl, data = SAheart, pch = 20, 
ylab = "Probability of CHD", xlab = "Low Density Lipoprotein Cholesterol")
grid()
lines(sort(SAheart$ldl),
  predict(chd_mod_ldl, data.frame(ldl = sort(SAheart$ldl)), type = "response"), 
  col = "dodgerblue", lty = 2, lwd = 2)
```

Al crescere dei valori di colesterolo cresce la probabilità che l'individuo sia malato. Possiamo derivare degli intervalli di confidenza per l'effetto di `ldl` sul log-odd di essere malato con `conf.int`: 

```{r}
confint.default(chd_mod_ldl,level=0.95, parm = "ldl")
## based on asymptotic normal distribution
coef(chd_mod_ldl)[2] + summary(chd_mod_ldl)$coef[2,2] * qnorm(c(0.025,0.975))
```

Invece che usare un solo predittore potremmo invece usare tutte le informazioni a nostra disposizione per predirre `chd`: 

```{r}
chd_mod_additive <- glm(chd ~ ., data = SAheart,  family = binomial)
summary(chd_mod_additive)
```

E chiederci se c'è una differenza in termini di bontà di adattamento del modello tra i due modelli, o in altre parole, andare a verificare se aver usato molti predittori in più ha avuto un effetto notevole sulla devianza/verosimiglianza: 

```{r}
chd_mod_ldl$deviance
chd_mod_additive$deviance
```

C'è una certa differenza nella devianza residua dei modelli: è una differenza importante? Possiamo usare il likelihood ratio test per verificare la cosa. Il test verifica l'ipotesi nulla 

\[H_0: \beta_{\texttt{sbp}} = \beta_{\texttt{tobacco}} = \beta_{\texttt{adiposity}} = \beta_{\texttt{famhist}} = \beta_{\texttt{typea}} = \beta_{\texttt{obesity}} = \beta_{\texttt{alcohol}} = \beta_{\texttt{age}} = 0 \]

contro l'alternativa 

\[H_1: \text{any } \beta_{\texttt{sbp}} \text{ or } \beta_{\texttt{tobacco}}  \text{ or }  \beta_{\texttt{adiposity}}  \text{ or }  \beta_{\texttt{famhist}}  \text{ or }  \beta_{\texttt{typea}}  \text{ or }  \beta_{\texttt{obesity}}  \text{ or } \beta_{\texttt{alcohol}}  \text{ or } \beta_{\texttt{age}} \neq 0 \]


```{r}
anova(chd_mod_ldl, chd_mod_additive, test = "LRT")
## or manually
# 2*as.numeric(logLik(chd_mod_additive)-logLik(chd_mod_ldl))
# chd_mod_ldl$deviance - chd_mod_additive$deviance
# pchisq(2*as.numeric(logLik(chd_mod_additive)-logLik(chd_mod_ldl)), lower.tail = FALSE, 
#        df = chd_mod_ldl$df.residual-chd_mod_additive$df.residual)
```

La differenza è significativa: possiamo rigettare $H_0$ e sospettiamo che almeno qualcuno dei predittori aggiuntivi oltre a `ldl` spieghi della variabilità nei dati. Come possiamo trovare un sottoinsieme in qualche modo ottimale di predittori? Possiamo usare AIC o BIC e applicare gli algoritmi backward, forward o step-wise usando la funzione `step`: 

```{r}
# First backward selection 
chd_mod_selected <- step(chd_mod_additive, trace = 1, k = 2)
coef(chd_mod_selected)
```

```{r}
chd_mod_null <- glm(formula = chd ~ 1, family = binomial, data = SAheart)
# forward selection 
step(chd_mod_null, trace = 1, k = 2, direction = "forward", 
                         scope = list(upper = chd_mod_additive))
```

Usando backward or forward troviamo lo stesso modello: cosa succede se usiamo BIC? 

```{r}
bic_k <- log(nrow(SAheart))
# forward selection 
step(chd_mod_null, trace = 1, k = bic_k, direction = "forward", 
                         scope = list(upper = chd_mod_additive))
```

Di nuovo scegliamo lo stesso sottoinsieme di predittori. 
La devianza di questo modello selezionato automaticamente differisce dalla varianza spiegata dal modello più complesso? 

```{r}
anova(chd_mod_selected, chd_mod_additive, test = "LRT")
```

Non molto, non possiamo rigettare l'ipotesi nulla


$$
H_0: \beta_{\texttt{sbp}} = \beta_{\texttt{adiposity}} = \beta_{\texttt{obesity}} = \beta_{\texttt{alcohol}} = 0
$$


Possiamo ora visualizzare l'effetto di `ldl` *per valori fissati degli altri predittori*: 

```{r}
nd <- data.frame(ldl = sort(SAheart$ldl),
                 age = median(SAheart$age), famhist= "Absent",
                 tobacco = median(SAheart$tobacco),  typea = median(SAheart$typea))
par(mfrow=c(1,1))
chd_mod_ldl <- glm(chd ~ ldl, data = SAheart, family = binomial)
summary(chd_mod_ldl)
plot(jitter(chd, factor = 0.1) ~ ldl, data = SAheart, pch = 20, 
ylab = "Probability of CHD", xlab = "Low Density Lipoprotein Cholesterol")
grid()
lines(nd$ldl, 
      predict(chd_mod_selected, newdata = nd, type = "response"), 
      col = "dodgerblue", lty = 2)
title(main = "P(CHD = 1) - famhist= Absent, age, tobacco, typea fixed to median")
```


```{r}
nd <- data.frame(ldl = sort(SAheart$ldl),
                 age = 45, famhist= "Absent",
                 tobacco = median(SAheart$tobacco),  typea = median(SAheart$typea))
par(mfrow=c(1,1))
chd_mod_ldl <- glm(chd ~ ldl, data = SAheart, family = binomial)
summary(chd_mod_ldl)
plot(jitter(chd, factor = 0.1) ~ ldl, data = SAheart, pch = 20, 
ylab = "Probability of CHD", xlab = "Low Density Lipoprotein Cholesterol")
grid()
lines(nd$ldl, 
      predict(chd_mod_selected, newdata = nd, type = "response"), 
      col = "dodgerblue", lty = 2)
nd$age <- 31
lines(nd$ldl, 
      predict(chd_mod_selected, newdata = nd, type = "response"), 
      col = "pink", lty = 2)
nd$age <- 55
lines(nd$ldl, 
      predict(chd_mod_selected, newdata = nd, type = "response"), 
      col = "orange", lty = 2)
title(main = "P(CHD = 1) - famhist= Absent, tobacco, typea fixed to median, age is 31, 45 and 55")
```

Possiamo anche calcolare intervalli di confidenza approssimati per il predittore lineare e per $P(chd = 1)$: 

```{r}
pred_vals <- predict(chd_mod_selected, newdata = nd, 
                     type = "link", se.fit = TRUE)
names(pred_vals)
head(pred_vals$fit); head(pred_vals$se.fit)
# the confidence interval for the linear predictor 
# based on the normal, the approximate distribution of the estimate of beta 
cint <- cbind(pred_vals$fit + qnorm(.025) * pred_vals$se.fit,
              pred_vals$fit + qnorm(.975) * pred_vals$se.fit)
## confidence interval for the predicted expected value
pint <- cbind(binomial()$linkinv(pred_vals$fit + qnorm(.025) * pred_vals$se.fit),
              binomial()$linkinv(pred_vals$fit + qnorm(.975) * pred_vals$se.fit))
```

Visualizziamo la curva stimata con gli intervalli di confidenza sulla scala di $\mu(x)$: 


```{r}
nd <- data.frame(ldl = sort(SAheart$ldl),
                 age = 45, famhist= "Absent",
                 tobacco = median(SAheart$tobacco),  typea = median(SAheart$typea))
par(mfrow=c(1,1))
chd_mod_ldl <- glm(chd ~ ldl, data = SAheart, family = binomial)
summary(chd_mod_ldl)
plot(jitter(chd, factor = 0.1) ~ ldl, data = SAheart, pch = 20, 
ylab = "Probability of CHD", xlab = "Low Density Lipoprotein Cholesterol")
grid()
lines(nd$ldl, binomial()$linkinv(pred_vals$fit), col = "dodgerblue")
lines(nd$ldl, pint[,1], col = "dodgerblue", lty = 2)
lines(nd$ldl, pint[,2], col = "dodgerblue", lty = 2)
```

Per i GLMs non è possibile derivare intervalli di predizione, si calcolano solo intervalli (approssimati) di confidenza per la il parametro di centralità. 


# Model selection per GLMs - Poisson 

Ci concentriamo ora sul dataset `hcrabs` in cui la variabile di interesse è il numero di satelliti attorno ad un granchio femmina. Desideriamo individuare i predittori che possono risultare utili nello spiegare la variabilità della variabile risposta. Innanzitutto leggiamo il dataset ed esploriamo le relazioni tra predittori e risposta: 


```{r}
hcrabs <- read.csv("hcrabs.csv", header = TRUE)
plot(hcrabs)
```


`Spine` e `Col` sono dei fattori ordinati: 

```{r}
hcrabs$Spine <- factor(hcrabs$Spine, levels = c("NoneOK", "OneOK", "BothOK"))
hcrabs$Col <- factor(hcrabs$Col, levels = c("LM", "M", "DM", "D"))

```

`Sat` (la variabile risposta) sembra essere legata a `Width` e `Wt`, le quali però sono anche legate tra loro. Le altre variabili nel dataset sono variabili categoriali Inoltre ci sono alcune variabili categoriali per cui lo scatterplot non facilita la comprensione delle relazioni tra i predittori ma che sembrano avere forse qualche effetto su `Sat`: 

```{r}
par(mfrow=c(1,2))
plot(Sat~Col, data =hcrabs)
plot(Sat~Spine, data =hcrabs)
```

Iniziamo la procedura di selezione del modello specificando i due modelli additivi più semplice e più complesso possibile: utilizzeremo poi la funzione `step` per verificare se esiste un modello con complessità intermedia tra i due che spieghi sufficientemente bene i dati. 

```{r}
model0<-glm(Sat~1, family=poisson(link=log),data=hcrabs)
modelFull<-glm(Sat~., family=poisson(link=log),data=hcrabs)
anova(model0, modelFull, test = "LRT") ## at least some variables are significant
```

Come criterio di valutazione della bontà di adattamento possiamo usare AIC or BIC (quindi prendiamo $k=log(n)$ nella penalizzazione): 

```{r}
## use AIC
selAIC <- step(model0, direction = "forward", 
     scope=list(lower = model0, upper = modelFull))
## use BIC 
selBIC <- step(model0, direction = "forward", k = log(nrow(hcrabs)), 
     scope=list(lower = model0, upper = modelFull))
```

Anche per i GLM usare BIC, e penalizzare più fortemente modelli con molti parametri, può risultare nella selezione di modelli più parsimoniosi. 

Teniamo come modello di lavoro il modello scelto da AIC e proviamo a visualizzare la stima ottenuta per ognuna delle categorie della variabile `Col`.

Possiamo guardare l'effetto sul predittore lineare: 

```{r}
plot(pmax(log(Sat),0)~Wt, data = hcrabs, col = as.numeric(hcrabs$Col), pch = 16)
nd <- data.frame(Wt = seq(min(hcrabs$Wt),max(hcrabs$Wt), length.out=80), Col = "D")
lines(nd$Wt, predict.glm(selAIC, newdata = nd,type = "link"), col = 1)
nd$Col <- "DM"
lines(nd$Wt, predict.glm(selAIC, newdata = nd,type = "link"), col = 2)
nd$Col <- "LM"
lines(nd$Wt, predict.glm(selAIC, newdata = nd,type = "link"), col = 3)
nd$Col <- "M"
lines(nd$Wt, predict.glm(selAIC, newdata = nd,type = "link"), col = 4)
```


Stimiamo 4 rette parallele (di cui due praticamente sovrapposte l'una all'altra). Sulla scala delle risposte invece vediamo una relazione non lineare, dato che il predittore lineare viene trasformato (in questo caso con la funzione esponenziale): 

```{r}
plot(Sat~Wt, data = hcrabs, col = as.numeric(hcrabs$Col), pch = 16)
nd <- data.frame(Wt = seq(min(hcrabs$Wt),max(hcrabs$Wt), length.out=80), Col = "D")
lines(nd$Wt, predict.glm(selAIC, newdata = nd,type = "response"), col = 1)
nd$Col <- "DM"
lines(nd$Wt, predict.glm(selAIC, newdata = nd,type = "response"), col = 2)
nd$Col <- "LM"
lines(nd$Wt, predict.glm(selAIC, newdata = nd,type = "response"), col = 3)
nd$Col <- "M"
lines(nd$Wt, predict.glm(selAIC, newdata = nd,type = "response"), col = 4)
```

Come per i modelli lineari, `step` verifica solo se la bontà di adattamento migliora togliendo od aggiungendo predittori, ma non permette di controllare se vi sia un'interazione tra i predittori. Possiamo però stimare modelli in cui le variabili categoriali interagiscono con le variabili continue e confrontare poi i modelli senza e con interazione, che sono annidati, tramite un'analisi della devianza: 


```{r}
selAIC_prod <- glm(formula = Sat ~ Wt * Col, family = poisson(link = log), data = hcrabs)
summary(selAIC_prod)
anova(selAIC, selAIC_prod, test = "LRT")
```

Rifiutiamo l'ipotesi nulla per cui i coefficienti angolari relativi alle diverse categorie siano tutti pari a zero: sembra che inserire un'interazione tra il peso del granchio e il colore catturi qualche caratteristica saliente dei dati. Possiamo visualizzare il modello stimato sulla scala del predittore lineare o la scala della risposta:  


```{r}
plot(pmax(log(Sat),0)~Wt, data = hcrabs, col = as.numeric(hcrabs$Col), pch = 16)
nd <- data.frame(Wt = seq(min(hcrabs$Wt),max(hcrabs$Wt), length.out=80), Col = "D")
lines(nd$Wt, predict.glm(selAIC_prod, newdata = nd,type = "link"), col = 1)
nd$Col <- "DM"
lines(nd$Wt, predict.glm(selAIC_prod, newdata = nd,type = "link"), col = 2)
nd$Col <- "LM"
lines(nd$Wt, predict.glm(selAIC_prod, newdata = nd,type = "link"), col = 3)
nd$Col <- "M"
lines(nd$Wt, predict.glm(selAIC_prod, newdata = nd,type = "link"), col = 4)
```


```{r}
plot(Sat~Wt, data = hcrabs, col = as.numeric(hcrabs$Col), pch = 16)
nd <- data.frame(Wt = seq(min(hcrabs$Wt),max(hcrabs$Wt), length.out=80), Col = "D")
lines(nd$Wt, predict.glm(selAIC_prod, newdata = nd,type = "response"), col = 1)
nd$Col <- "DM"
lines(nd$Wt, predict.glm(selAIC_prod, newdata = nd,type = "response"), col = 2)
nd$Col <- "LM"
lines(nd$Wt, predict.glm(selAIC_prod, newdata = nd,type = "response"), col = 3)
nd$Col <- "M"
lines(nd$Wt, predict.glm(selAIC_prod, newdata = nd,type = "response"), col = 4)
legend("bottomright", col = c(1,2,3,4), legend = c("D","DM","LM","M"), lty = 1)
```


Si nota che per un colore (`LM`) stimiamo una relazione molto diversa: per capire meglio se questa stima è sensata dovremmo discutere con un esperto di granchi, ma possiamo già notare che ci sono molti pochi granchi in questa categoria quindi la stima è piuttosto incerta. 

Possiamo anche confrontare gli intervalli di confidenza (al 90\%) per due categorie (solo due per rendere il grafico meno pesante): 

```{r}
alpha = 0.1
plot(Sat~Wt, data = hcrabs, col = as.numeric(hcrabs$Col), pch = 16)
nd <- data.frame(Wt = seq(min(hcrabs$Wt),max(hcrabs$Wt), length.out=80), Col = "D")
pred <- predict.glm(selAIC_prod, newdata = nd, se.fit = TRUE)
lines(nd$Wt, exp(pred$fit), col = 1)
lines(nd$Wt, exp(pred$fit-qnorm(alpha/2)*pred$se.fit), col = 1, lty = 2)
lines(nd$Wt, exp(pred$fit+qnorm(alpha/2)*pred$se.fit), col = 1, lty = 2)
nd$Col <- "LM"
pred <- predict.glm(selAIC_prod, newdata = nd, se.fit = TRUE)
lines(nd$Wt, exp(pred$fit), col = 3)
lines(nd$Wt, exp(pred$fit-qnorm(alpha/2)*pred$se.fit), col = 3, lty = 2)
lines(nd$Wt, exp(pred$fit+qnorm(alpha/2)*pred$se.fit), col = 3, lty = 2)
legend("bottomright", col = c(1,3), legend = c("D","M"), lty = 1)
```



# Residui


La funzione `residuals` permette di estrarre i residui di un GLM, in cui la definizione di residui non è unica come per i modelli lineari, di conseguenza possiamo chiedere diversi tipi di residui usando l'argomento `type` nella funzione `residuals`:  

```{r}
head(residuals(model0, type="deviance"))
# poisson()$dev.resid
sum(residuals(model0, type="deviance")^2); model0$deviance
head(residuals(model0, type="pearson"))
head((hcrabs$Sat - model0$fitted.values)/sqrt(model0$fitted.values))
head(residuals(model0, type="response"))
head((hcrabs$Sat - model0$fitted.values))
```

```{r}
plot(hcrabs$Wt, residuals(model0, type="deviance"), pch = 16)
```

```{r}
plot(hcrabs$Wt, residuals(selAIC, type="deviance"), pch = 16)
```

