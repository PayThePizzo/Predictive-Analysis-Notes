# Variable Selection
Find the simplest model to explain the data. Smaller models lead to less variable
inference/prediction and can be more explainable than complex models. 

> Occam’s Razor principle: the smallest model that fits the data is best.


1. Simplest model for best fit: Use any of the criteria discussed before to choose.
2. The most direct approach is called all subsets or best subsets regression: compute the least squares fit for all possible subsets and then choose between them based on some criterion.

However we often can not examine all possible models, since they are $2^{p-1}$ of them; for
example when $p−1 = 30$ there are 1073741824 models!

Instead we need an automated approach that searches through a subset of them. We
discuss some commonly used approaches next

## Forward Stepwise Selection

1. Let $\mathcal{M_{0}}$ denote the null model which contains no predictors.
2. $\forall k=1,...,p-2$
   1. Consider all $p-k$ models that augment the predictors in $\mathcal{M_{k}}$ with one additional predictor.
   2. Choose the best among these $p-k$ models and call it $\mathcal{M_{k_1}}$, where best is defined as $minimize(SS_{RES})$
3. Select a single best model from among $\mathcal{M_{0}}...\mathcal{M_{p-1}}$ using cross-validated prediction error, AIC, BIC, or Adjusted $R^{2}$

Computational advantage over best subset selection is clear. It is not guaranteed to find the best possible model out of all $2^{p-1}$ models containing subsets of the $p-1$ predictors


## Backward Stepwise Selection

## Stepwise Search

---

## Discussion

---

## Inference after Selection

## Validation Based Selection




