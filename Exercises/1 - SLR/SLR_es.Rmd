---
title: "Esercizio 1 - Regressione Lineare Semplice"
author: "Inserite il vostro nome"
date: "`r format(Sys.Date(), '%d %B %Y')`"
output: html_document
---

# Esercizio SLR

Si prenda in esame il dataset `bodyfat`: 

```{r}
urlLocation <- "https://dasl.datadescription.com/download/data/3079"
bodyfat <- read.table(urlLocation, header=TRUE)
```

Il dataset (che è stato recuperato dal sito https://dasl.datadescription.com/datafile/bodyfat/) comprende molte variabili: per il momento prendiamo in considerazione sono le variabili `Weight` e `Height`, che contengono i valori di peso (misurato in libbre) e altezza (misurata in pollici)  per 250 uomini di varie età. 
In particolare vogliamo valutare come l'altezza influenzi il peso. 

```{r}
bodyfat <- bodyfat[,c("Weight","Height")]
plot(Weight~Height, data = bodyfat)
```

## Domanda 1

> Si dia una stima del modello: valori dei coefficienti e loro significatività. Si interpreti il valore di ognuno dei coefficienti. 


Il modello stimato e':

$$\mathbb{E}[Y|X=x] = \beta_{0} + \beta_{1}X$$
In R questo si stima con:
```{r}
fit <- lm(Weight~Height, data = bodyfat)

summary(fit)
```

I coefficienti stimati sono:

* $\hat{\beta}_{0}=$ `r signif(coef(fit)[1],4)`. 
    + La retta stimata passa per il punto (0, `r signif(coef(fit)[1],4)`). 
    + Il valore dell'intercetta è significativamente diverso da 0 (pvalue < 0.001). 
* $\hat{\beta}_{1}=$ `r signif(coef(fit)[2],4)`. 
    + Due uomini che abbiano una differenza di altezza di un pollice hanno in media una differenza di peso di `r signif(coef(fit)[2],3)` libbre. 
    + Il valore del coefficiente angolare è significativamente diverso da 0 (pvalue < 0.001). 

```{r}
plot(Weight~Height, data = bodyfat, 
     xlab = "Height in inches",
     ylab = "Weight in lbs",
     main ='Weight predicted by Height')
abline(coefficients(fit), col="red")
```

---

## Domanda 2

> Qual è il valore del coefficiente $R^2$ - come si può interpretare questo valore? 

$R^2$ e' anche chiamato *il coefficiente di determinazione*, ovvero la proporzione della variabilita' spiegata dal modello. E' una misura che giudica la bonta' di adattamento del modello.

$$R^{2} = 1 - \frac{SS_{RES}}{SS_{TOT}} = \frac{SS_{REG}}{SS_{TOT}} \mbox{, and } R^{2} \in [0,1]$$

All'aumentare della $SS_{RES}$, diminuisce il valore di $R^2$ ed e' per questo che quando il modello non riesce a spiegare buona parte della variabilita', si ha un $R^2$ particolarmente basso. 

Questo segnala anche che la relazione lineare tra il target e la risposta non sia sufficiente a speigare tutta la variabilita' osservata e potrebbe essere opportuno includere altri predittori nel modello. Purtroppo il valore di $R^2$ tende a portare ad overfitting, dal momento che aumenta all'aumentare del numero di predittori.

Per il modello stimato, il valore di $R^2$ e' `r summary(fit)$r.squared`. Cio' puo' essere interpretato con la frase: **"circa il (`r signif(summary(fit)$r.squared, 4)*100`% della variabilita' osservata nel target (varianza totale dei dati) e' spiegata dalla relazione lineare con il predittore `Height`"**.
 
---

## Domanda 3

> Vi è evidenza della veridicità dell'affermazione: "Due uomini la cui altezza differisca di un pollice hanno in media una differenza di peso di 5 libbre"? 

Vogliamo verificare se sia possibile falsificare l'affermazione "Due uomini la cui altezza differisca di un pollice hanno in media una differenza di peso di 5 libbre". Questo corrisponde a falsificare l'affermazione $\beta_1 = 5$, cioè a testare il sistema di ipotesi: 

$$H_{0}: \beta_{1} = 5 \mbox{ vs } H_{0}: \beta_{1} \neq 5$$
Per fare cioè calcoliamo la statistica test: 

Il p-value del test è dato da:
$$ TS = t_{obs} = \frac{\widehat{\beta}_{j} - \beta_{j}^{*}}{SE[\widehat{\beta}_{j}]} \sim t_{n-p} 
    \left\{ \begin{array}{rcl} 
H_{0}: \beta_{j} = \beta_{j}^{*} \\
H_{A}: \beta_{j} \neq \beta_{j}^{*}
    \end{array}\right.$$

Ovvero:
\[TS = \frac{\hat{\beta}_1 - 5}{SE(\hat{\beta}_1 )}  = \frac{`r coef(fit)[2]` - 5}{`r summary(fit)$coef[2,2]`} =  `r (summary(fit)$coef[2,1]-5)/summary(fit)$coef[2,2]`\]


```{r}
## Method 1 - p-value
# Ts
t_obs = (coefficients(fit)[2]-5)/(sqrt(vcov(fit)[2,2]))

# P-value
pv <- 2*pt(abs(t_obs), df=df.residual(fit), lower.tail = FALSE)
pv
```

Alternativamente possiamo verificare lo stesso tramite l'intervallo di confidenza

$$\widehat{\beta}_{1} \pm t_{\alpha/2,n-2} \times SE[\widehat{\beta}_{1}] = `r coefficients(fit)[2]` \pm t_{\alpha/2, `r df.residual(fit)`} \times `r sqrt(vcov(fit)[2,2])`$$

```{r}
## Method 2 - IC
(conf_int <- coefficients(fit)[2] + qt(c(.025, .975), df = df.residual(fit)) * (sqrt(vcov(fit)[2,2])))
```

In ogni caso giungiamo alla conclusione che al livello di significativita' del 5% non possiamo rifiutare l'ipotesi nulla che "Due uomini la cui altezza differisca di un pollice hanno in media una differenza di peso di 5 libbre" dal momento che:

* Il p-value `r pv`` e' molto grande
* `5.0` si trova nell'intervallo di confidenza (`r conf_int`)

---

## Domanda 4

> Si diano un intervallo di confidenza e di predizione al 90\% per due nuovi soggetti di altezza 70 e 78 pollici. Si dia un commento sull'ampiezza dei due intervalli di confidenza. 

Intervalli di confidenza

$$\widehat{m}(x) \pm t_{\alpha/2,n-2} \times SE[\widehat{m}(x)]$$

```{r}
nd <- data.frame(Height = c(70,78))
cvals <- predict(fit, newdata = nd, 
          level = 0.9, interval = "conf")
cvals
cvals[,3] - cvals[,2]
```


Intervalli di predizione

$$\widehat{m}(x) \pm t_{\alpha/2,n-2} \times se\sqrt{1+\frac{1}{n} + \frac{(x-\bar{x})^2}{\sum_{i=1}^{n}(x_{i}-\bar{x})^2}}$$

```{r}
pvals <- predict(fit, newdata = nd, 
          level = 0.9, interval = "pred")
pvals
pvals[,3] -  pvals[,2]
```
L'intervallo di confidenza per l'uomo di altezza 70 pollici è molto più stretto (preciso) di quello per l'uomo di 78 pollici: questo perché la media campionaria dell'altezza osservata nel campione in esame è di `r signif(mean(bodyfat$Height),3)`, un valore molto vicino a 70. Dato che la retta stimata passa necessariamente per il punto $(\bar{x}, \bar{y})$ vi è meno incertezza nella stima del valore di $Y|X=x_0$ quando $x_0$ è vicino a $\bar{x}$. Il valore di 78 pollici invece è piuttosto estremo nel nostro campione: la stima del valore atteso di $Y$ per questo valore di $X$ è più incerta. 

Inoltre, quando si tratta di predizione, bisogna considerare che viene aggiunta incertezza alla stima.

Possiamo anche visualizzare l'incertezza per la stima del valore atteso e dei valori della variabile risposta in funzione della variabile esplicativa:

```{r}
nd <- data.frame(Height = seq(62,80))
cvals <- predict(fit, newdata = nd, 
        level = 0.9, interval = "conf")
pvals <- predict(fit, newdata = nd, 
         level = 0.9, interval = "pred")
plot(Weight~Height, data = bodyfat, xlim = c(62,80), pch = 16, col = "grey")
lines(nd$Height, cvals[,1], col = 1, lwd = 2)
lines(nd$Height, cvals[,2], col = 2, lwd = 2)
lines(nd$Height, cvals[,3], col = 2, lwd = 2)
lines(nd$Height, pvals[,2], col = 4, lwd = 2)
lines(nd$Height, pvals[,3], col = 4, lwd = 2)
```

---

## Domanda 5

> Si elenchino le assunzioni fatte per poter stimare il modello. Si usino dei grafici utili ad investigare se le assunzioni risultano essere valide per il modello stimato.  

Le assunzioni si possono scrivere in maniera sintetica come $Y_i|X=x_i \stackrel{iid}{\sim} N(\beta_0 + \beta_1 x_i, \sigma)$ per ogni $i= 1, \ldots, n$. 

Si deve quindi verificare che la relazione tra X e Y sia lineare e che le osservazioni seguano una normale e abbiano varianza costante. 

### Verifica di Linearita': Residui vs Predittore

Dal grafico tra la variabile predittore e i residui non emerge nessuna forte indicazione di una qualche forma relazionale tra `Height` e `Weight` non spiegata dal modello lineare:

```{r}
plot(bodyfat$Height, resid(fit))
abline(h=0)
```

### Verifica di Normalita': QQPlot

Si notano invece alcuni residui con un valore piuttosto alto. Questi sono visibili anche nel qqplot che aiuta a verificare la normalità dei residui: 

```{r}
qqnorm(resid(fit))
qqline(resid(fit))
```

Sebbene si notino i valori alti e una leggera curvatura dei punti, il qqplot risulta abbastanza soddisfacente e i residui sembrano comportarsi come un campione di una normale.


### Verifica di Omoschedasticita': Residui vs $\hat{y}$

Infine, il grafico di valori stimati contro residui è spesso utile per controllare l'assunzione di varianza costante: 

```{r}
plot(fitted(fit), resid(fit))
abline(h=0)
```

Non sembrano esserci segni che la varianza cambi in funzione del valore stimato della funzione. 

### Verifica di Indipendenza

Verificare che le osservazioni siano indipendenti è complicato in questo caso: non abbiamo un test per farlo. Possiamo sperare che lo schema di campionamento usato abbia evitato per esempio di inserire persone della stessa famiglia (fratelli, cugini, etc...) o non abbiano selezionato molti giocatori di basket professionisti (alti e probabilmente con una costituzione corporea diversa da quella della popolazione generale). Con le informazioni disponibili possiamo sperare che il campione sia composto da osservazioni indipendenti e rappresentative della popolazione generale. 

---

## Domanda 6

> Qual è l'interpretazione dell'intercetta nel modello? Cosa succede se si stima un modello usando una nuova variabile `HightCentred = Height - mean(Height)`. 

L'interpretazione dell'interecetta nel modello originale è poco utile: non esistono persone alte 0 pollici. Se si usa invece la variabile centrata l'intercetta diventa il valore di $\bar{y}$, dato che $\bar{x} = 0$: 

```{r}
bodyfat$HeightCentred <- bodyfat$Height - mean(bodyfat$Height)
colMeans(bodyfat)
summary(lm(Weight~HeightCentred, data = bodyfat))
```

L'intercetta ora descrive il valore medio del peso di un uomo di statura media. 
Il valore del coefficiente angolare non cambia: questo perché non cambiano la covarianza tra i due campioni e la somma dei scarti quadrati di $x$ (per le proprietà di varianza e covarianza). Questo implica che non cambia la differenza di peso tra due uomini la cui altezza differisce per un pollice.  

---

## Domanda 7

> Si creino le variabili `HightScale = (Height - mean(Height))/sd(Height)` e `WeightScale = (Weight - mean(Weight))/sd(Weight)`. Come si possono interpretare intercetta a coefficiente angolare per questo modello? Si confronti il valore di $R^2$ e il p-value del test di significatività per $\beta_1$ nel modello stimato usando i dati modificati e i dati originali: cpsa si può notare? [Per creare le nuove variabili si può anche usare direttamente la funzione `scale`.]

```{r}
bodyfat$HightScale <- scale(bodyfat$Height); bodyfat$WeightScale<- scale(bodyfat$Weight)
lmScale <- lm(WeightScale ~ HightScale, data = bodyfat)
summary(lmScale)
```

La significatività del coefficiente angolare e il valore di $R^2$ sono gli stessi: la relazione tra le due variabili non è cambiata. La retta passa ancora per il centre delle due variabili (il punto (0,0)). Il valore stiamto per il coeffciente angolare ora indica il cambiamento atteso in standard deviations di Peso per un cambimaneto di 1 standard deviation dell'Altezza. Questo tipo di trasformazione può essere particolamente utile quando si stimano modelli multivariati e nella situazione in cui si stiano usando variabili con valori numerici molto alti o molto piccoli (e/o scale di misura che possono coprire valori molto diversi): in questo modo si possono evitare problemi di tipo numerico. 

---

## Domanda 8

> Le variabili sono state misurate rispettivamente in pollici e libbre. Si trasformino i dati in centimetri e chilogrammi: come cambiano le stime dei parametri del modello lineare? Come cambia la loro interpretazione? [Nota: per passare da pollici a cm è necessario moltiplicare i valori originali per 2.54; per passare da libbre a chilogrammi è necessario dividere i valori originali per 2.205]. 

Per prima cosa creiamo le nuove variabili e facciamone un grafico

```{r}
bodyfat$cmHeight <- bodyfat$Height*2.54
bodyfat$kgWeight <- bodyfat$Weight/2.205
## the relationship between the two variables is the same
plot(bodyfat$cmHeight, bodyfat$kgWeight)
cor(bodyfat$cmHeight, bodyfat$kgWeight)
cor(bodyfat$Height, bodyfat$Weight)
## the covariance does change - because it is not scaled
cov(bodyfat$cmHeight, bodyfat$kgWeight)
cov(bodyfat$Height, bodyfat$Weight)
### the variances are also different - properties of the variances
```

Mentre la relazione delle due variabili l'una con l'altra non cambia, i valori delle varianze dei due campioni e la covarianza cambieranno - questo è una conseguenza delle proprietà di varianza e covarianza: 

```{r}
var(bodyfat$Height); var(bodyfat$cmHeight)
## cmHeight is 2.54*Height
## Its variance is Var(a*Y) = a^2 * Var(Y)
(2.54^2) * var(bodyfat$Height)
```

Di conseguenza, nello stimare un nuovo modello si avranno valori diversi sia per il coefficiente angolare che per l'intercetta

```{r}
fitEurope <- lm(kgWeight ~ cmHeight, data = bodyfat)
summary(fitEurope)
```

Il coefficiente angolare ora rappresenta la differenza in Kg tra due uomini che differiscono in altezza di un centimetro. 


Il modello sui dati originali corrisponde a: 

\[E[Y|X=x] = \beta_0 + \beta_1 x . \]

Quando si trasformano le variabili X e Y si ottiene un nuovo modello: 

\[E[ a * Y|X=x] = \beta^*_0 + \beta^*_1 (b * x) . \]

Questo implica che 

\[ a * E[Y|X=x] = \beta^*_0 +  (b * \beta^*_1) x  \]

da cui segue che $\beta_0 = \beta^*_0/ a$ e $\beta_1 = b * \beta^*_1/ a$: 

```{r}
a <- 1/2.205
b <- 2.54
c(coef(fitEurope)[1]/a , coef(fitEurope)[2]*b/a)
coef(fit)
## confermato
```

Si noti che nonostante il cambiamento dei valori di intercetta e coefficiente angolare non sono cambiati i valori della statistica test. 

---

## Domanda 9 

> Quale potrebbe essere l'intervallo di confidenza del peso di una donna alta 72 pollici? 

Il campione comprende solo uomini - i valori stimati dal modello non sono applicabili ad una popolazione diversa da quella campionata. 

---

## Domanda 10
 
> Si estragga (usando in maniera appropriata la funzione `sample`) un sottocampione del dataset di 50 osservazioni: si confrontino le stime ottenute usando tutto il campione e le stime ottenute usando il sottocampione. 

```{r}
set.seed(178); sampledObs <- sample(seq(1, 250), size = 50)
fitSub <- lm(Weight ~ Height, data = bodyfat[sampledObs,])
summary(fitSub)
summary(fit)
```

Le stime dei parametri cambiano, ma rimangono nel range dato dalla stima originale. Quello che cambia molto è la stima della variabilità delle stime, che aumenta. Da questo segue che il p-value per il test della significatività dei parametri sia leggermente più alto. Questo è legato al fatto che la variabilità delle stime è legata alla numerosità campionaria: con un campione con meno osservazioni si ottengono stime più variabili. 
Cambia invece di poco il valore di $R^2$: avendo preso un sottocampione casuale non cambia di molto cosa capiamo della relazione tra X e Y: la proporzione di variabilità di $y$ spiegata da $x$ rimane simile [questo potrebbe non sempre essere vero a seconda del sottocampione].  
