---
title: "lab 03 - inferenza in R"
author: "Me Myself and I"
date: "04/10/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Inferenza per i parametri del modello 

Inferenza per $\beta_0$ e $\beta_1$: 

```{r}
data(cars)
fit <- lm(dist~speed, data = cars)
summary(fit)
```

$$H_0: \beta_0 = 0 \quad VS \quad H_1: \beta_0 \neq 0$$
$$H_0: \beta_1 = 0 \quad VS \quad H_1: \beta_1 \neq 0$$

```{r}
ctab <- summary(fit)$coefficients
(ctab[,1] - 0)/ctab[,2]
ctab[,3] 
2*(1-pt(abs(ctab[,3]), df = fit$df.residual))
ctab[,4] 
```

è possibile costruire test per qualunque ipotesi nulla del tipo: 

$$H_0: \beta_1 = \beta^*_1 \quad VS \quad H_1: \beta_1 \neq \beta^*_1$$

Prendiamo $\beta_1^* = 3.7$:

```{r}
TS <- (ctab[2,1] - 3.7)/ctab[2,2]; TS
2*(1-pt(abs(TS), df = fit$df.residual))
```
In alternativa si può guardare agli intervalli di confidenza: 

```{r}
confint(fit, level = 0.9)
confint(fit, level = 0.9, parm = "speed")
```

```{r}
# 90% confidence interval
ctab[2,1] + qt(c(0.05,0.95), df= fit$df.residual) * ctab[2,2] 
```

## Inferenza sulla funzione stimata

Useremo la funzione `predict`:

```{r}
nd <- data.frame(speed = c(5, 15, 25))
predict(fit, newdata = nd, level = 0.9, 
        interval = "confidence")
predict(fit, newdata = nd, level = 0.9, 
        interval = "prediction")
s_e <- summary(fit)$sigma
sumsq_x <- sum((cars$speed - mean(cars$speed))^2)
cbind((coef(fit)[1] + coef(fit)[2] * nd$speed) + qt(0.05, df = 48) *
  s_e*sqrt(1/50 + ((nd$speed - mean(cars$speed))^2)/sumsq_x),
  (coef(fit)[1] + coef(fit)[2] * nd$speed) + qt(0.95, df = 48) *
  s_e*sqrt(1/50 + ((nd$speed - mean(cars$speed))^2)/sumsq_x))
cbind((coef(fit)[1] + coef(fit)[2] * nd$speed) + qt(0.05, df = 48) *
  s_e*sqrt(1+1/50 + ((nd$speed - mean(cars$speed))^2)/sumsq_x),
  (coef(fit)[1] + coef(fit)[2] * nd$speed) + qt(0.95, df = 48) *
  s_e*sqrt(1+1/50 + ((nd$speed - mean(cars$speed))^2)/sumsq_x))
```

\[
\text{Confidence intervals: }\hat{m}(x) \pm t_{\alpha/2, n - 2} \times s_e\sqrt{\frac{1}{n}+\frac{(x-\bar{x})^2}{\sum_{i = 1}^n(x_i-\overline{x})^2}} 
\]

\[
\text{Prediction intervals: }\hat{m}(x) \pm t_{\alpha/2, n - 2} \times s_e\sqrt{1+\frac{1}{n}+\frac{(x-\bar{x})^2}{\sum_{i = 1}^n(x_i-\overline{x})^2}} 
\]


```{r}
nd <- data.frame(speed = seq(4,27, length.out = 150))
cint <- predict(fit, newdata = nd, level = 0.9, 
        interval = "confidence")
pint <- predict(fit, newdata = nd, level = 0.9, 
        interval = "prediction")
plot(cars, pch = 16, col = "grey"); abline(coef(fit), col = 4)
lines(nd$speed, cint[,"lwr"], lty = 2); lines(nd$speed, cint[,"upr"], lty = 2)
lines(nd$speed, pint[,"lwr"], lty = 2, col = 2); lines(nd$speed, pint[,"upr"], lty = 2, col = 2)
```

# Verificare la teoria statistica tramite simulazione 

```{r}
sigma_model = 15.4 # \sigma
true_betas <- c(-17.6, 3.9) # (\beta_0, \beta_1)
set.seed(4388)
fixed_xs <- sort(round(runif(50, 4, 26))) # (x_1, \ldots, x_n) - predeterminate 

generaEstima <- function(betas, xs, sigma){
  n <- length(xs)
  y <- rnorm(n, betas[1] + betas[2]*xs, sigma)
  coef(lm(y~xs))
}
generaEstima(betas = true_betas, xs = fixed_xs, sigma  = sigma_model)
betas_gen <- t(replicate(50, generaEstima(betas = true_betas, xs = fixed_xs, sigma  = sigma_model)))
plot(fixed_xs, true_betas[1]+ true_betas[2]*fixed_xs, type="l")
for(j in 1:50) abline(betas_gen[j,], col = "grey")
lines(fixed_xs, true_betas[1]+ true_betas[2]*fixed_xs, col = 2, lwd = 2)
```


Aumentiamo il numero di simulazioni: 

```{r}
set.seed(1686)
betas_gen <- t(replicate(1000, generaEstima(betas = true_betas, xs = fixed_xs, sigma  = sigma_model)))
colMeans(betas_gen)
true_betas
```

Dalla teoria abbiamo visto quale è il valore della standard deviation degli stimatori: 

```{r}
sumsq_x <- sum((fixed_xs-mean(fixed_xs))^2)
# per beta_0 (slide 134)
sigma_model*sqrt(1/50 + mean(fixed_xs^2)/sumsq_x)
sd(betas_gen[,1])
hist(betas_gen[,1])
```





